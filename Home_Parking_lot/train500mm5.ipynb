{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download labeling from GitHub - https://github.com/tzutalin/labelImg\n",
    "\n",
    "\n",
    "`!pip install pyqt5`\n",
    "\n",
    "`!pip install lxml`\n",
    "\n",
    "\n",
    "Installation guide - https://github.com/heartexlabs/labelImg#installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command in the terminal\n",
    "\n",
    "`pyrcc5 -o libs/resources.py resources.qrc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection.retinanet import RetinaNet_ResNet50_FPN_Weights\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Number of classes including background\n",
    "num_classes = 91 \n",
    "\n",
    "# Load a pre-trained model\n",
    "model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True, num_classes=num_classes)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Continue with your code... (Origional numbers)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "\n",
    "class YOLODataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform if transform else transforms.ToTensor()\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root_dir, \"images\"))))\n",
    "        self.labels = list(sorted(os.listdir(os.path.join(root_dir, \"labels\"))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, \"images\", self.imgs[idx])\n",
    "        label_path = os.path.join(self.root_dir, \"labels\", self.labels[idx])\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_width, img_height = img.size\n",
    "\n",
    "        # Apply transformation after getting original size\n",
    "        img = self.transform(img)\n",
    "\n",
    "        # Read YOLO label file\n",
    "        with open(label_path, \"r\") as file:\n",
    "            lines = file.read().splitlines()\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for line in lines:\n",
    "            class_id, x_center, y_center, width, height = map(float, line.split())\n",
    "            labels.append(int(class_id))\n",
    "\n",
    "            x_min = img_width * (x_center - width / 2)\n",
    "            y_min = img_height * (y_center - height / 2)\n",
    "            x_max = img_width * (x_center + width / 2)\n",
    "            y_max = img_height * (y_center + height / 2)\n",
    "            boxes.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = torch.tensor(boxes, dtype=torch.float32)\n",
    "        target['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "# Define your own paths here\n",
    "train_dataset = YOLODataset(\"data/train set\")\n",
    "valid_dataset = YOLODataset(\"data/validation set\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "\n",
    "    return images, targets\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.5, weight_decay=0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.29519328474998474\n",
      "Epoch: 2, Loss: 0.23080462217330933\n",
      "Epoch: 3, Loss: 0.2574554681777954\n",
      "Epoch: 4, Loss: 0.20284490287303925\n",
      "Epoch: 5, Loss: 0.19133850932121277\n",
      "Epoch: 6, Loss: 0.17199423909187317\n",
      "Epoch: 7, Loss: 0.1196833923459053\n",
      "Epoch: 8, Loss: 0.21816259622573853\n",
      "Epoch: 9, Loss: 0.12178077548742294\n",
      "Epoch: 10, Loss: 0.10643225908279419\n",
      "Epoch: 11, Loss: 0.1746397614479065\n",
      "Epoch: 12, Loss: 0.0936783105134964\n",
      "Epoch: 13, Loss: 0.1043352484703064\n",
      "Epoch: 14, Loss: 0.15091785788536072\n",
      "Epoch: 15, Loss: 0.13693469762802124\n",
      "Epoch: 16, Loss: 0.08447380363941193\n",
      "Epoch: 17, Loss: 0.12717850506305695\n",
      "Epoch: 18, Loss: 0.12243068963289261\n",
      "Epoch: 19, Loss: 0.12133996188640594\n",
      "Epoch: 20, Loss: 0.13260038197040558\n",
      "Epoch: 21, Loss: 0.11567588895559311\n",
      "Epoch: 22, Loss: 0.14327619969844818\n",
      "Epoch: 23, Loss: 0.10531725734472275\n",
      "Epoch: 24, Loss: 0.1216469556093216\n",
      "Epoch: 25, Loss: 0.1006377711892128\n",
      "Epoch: 26, Loss: 0.07615561783313751\n",
      "Epoch: 27, Loss: 0.0701209008693695\n",
      "Epoch: 28, Loss: 0.11706706881523132\n",
      "Epoch: 29, Loss: 0.10286114364862442\n",
      "Epoch: 30, Loss: 0.12461996078491211\n",
      "Epoch: 31, Loss: 0.07279486209154129\n",
      "Epoch: 32, Loss: 0.11767350137233734\n",
      "Epoch: 33, Loss: 0.09180200845003128\n",
      "Epoch: 34, Loss: 0.06777437776327133\n",
      "Epoch: 35, Loss: 0.09420634061098099\n",
      "Epoch: 36, Loss: 0.11504589021205902\n",
      "Epoch: 37, Loss: 0.10482577979564667\n",
      "Epoch: 38, Loss: 0.10557439923286438\n",
      "Epoch: 39, Loss: 0.059895921498537064\n",
      "Epoch: 40, Loss: 0.08941344916820526\n",
      "Epoch: 41, Loss: 0.10267004370689392\n",
      "Epoch: 42, Loss: 0.0835946798324585\n",
      "Epoch: 43, Loss: 0.10015065222978592\n",
      "Epoch: 44, Loss: 0.055368948727846146\n",
      "Epoch: 45, Loss: 0.10105942189693451\n",
      "Epoch: 46, Loss: 0.051767293363809586\n",
      "Epoch: 47, Loss: 0.07979141175746918\n",
      "Epoch: 48, Loss: 0.07882007956504822\n",
      "Epoch: 49, Loss: 0.057499904185533524\n",
      "Epoch: 50, Loss: 0.09373496472835541\n",
      "Epoch: 51, Loss: 0.09854451566934586\n",
      "Epoch: 52, Loss: 0.09453378617763519\n",
      "Epoch: 53, Loss: 0.09252374619245529\n",
      "Epoch: 54, Loss: 0.07561670988798141\n",
      "Epoch: 55, Loss: 0.0894770473241806\n",
      "Epoch: 56, Loss: 0.0874774158000946\n",
      "Epoch: 57, Loss: 0.08698198944330215\n",
      "Epoch: 58, Loss: 0.09240950644016266\n",
      "Epoch: 59, Loss: 0.08365985751152039\n",
      "Epoch: 60, Loss: 0.08949033170938492\n",
      "Epoch: 61, Loss: 0.08660263568162918\n",
      "Epoch: 62, Loss: 0.1060175970196724\n",
      "Epoch: 63, Loss: 0.08302587270736694\n",
      "Epoch: 64, Loss: 0.04496796801686287\n",
      "Epoch: 65, Loss: 0.08565584570169449\n",
      "Epoch: 66, Loss: 0.06661619246006012\n",
      "Epoch: 67, Loss: 0.08413545787334442\n",
      "Epoch: 68, Loss: 0.07004956156015396\n",
      "Epoch: 69, Loss: 0.03483933210372925\n",
      "Epoch: 70, Loss: 0.07664018869400024\n",
      "Epoch: 71, Loss: 0.07505573332309723\n",
      "Epoch: 72, Loss: 0.03981640934944153\n",
      "Epoch: 73, Loss: 0.03774036839604378\n",
      "Epoch: 74, Loss: 0.07323676347732544\n",
      "Epoch: 75, Loss: 0.07073389738798141\n",
      "Epoch: 76, Loss: 0.04631437361240387\n",
      "Epoch: 77, Loss: 0.03199121356010437\n",
      "Epoch: 78, Loss: 0.0815211683511734\n",
      "Epoch: 79, Loss: 0.062272943556308746\n",
      "Epoch: 80, Loss: 0.0812971442937851\n",
      "Epoch: 81, Loss: 0.0439283587038517\n",
      "Epoch: 82, Loss: 0.07615120708942413\n",
      "Epoch: 83, Loss: 0.050315968692302704\n",
      "Epoch: 84, Loss: 0.06713660806417465\n",
      "Epoch: 85, Loss: 0.07521214336156845\n",
      "Epoch: 86, Loss: 0.07265907526016235\n",
      "Epoch: 87, Loss: 0.0771765261888504\n",
      "Epoch: 88, Loss: 0.0747242271900177\n",
      "Epoch: 89, Loss: 0.08231319487094879\n",
      "Epoch: 90, Loss: 0.05104333907365799\n",
      "Epoch: 91, Loss: 0.05911484360694885\n",
      "Epoch: 92, Loss: 0.03910629451274872\n",
      "Epoch: 93, Loss: 0.06126144900918007\n",
      "Epoch: 94, Loss: 0.06118728220462799\n",
      "Epoch: 95, Loss: 0.06388743966817856\n",
      "Epoch: 96, Loss: 0.05915679782629013\n",
      "Epoch: 97, Loss: 0.0720435082912445\n",
      "Epoch: 98, Loss: 0.06965016573667526\n",
      "Epoch: 99, Loss: 0.05819293484091759\n",
      "Epoch: 100, Loss: 0.06989975273609161\n",
      "Epoch: 101, Loss: 0.07450120896100998\n",
      "Epoch: 102, Loss: 0.07076868414878845\n",
      "Epoch: 103, Loss: 0.06848719716072083\n",
      "Epoch: 104, Loss: 0.05677863582968712\n",
      "Epoch: 105, Loss: 0.0702829584479332\n",
      "Epoch: 106, Loss: 0.039104171097278595\n",
      "Epoch: 107, Loss: 0.05073351785540581\n",
      "Epoch: 108, Loss: 0.05837245658040047\n",
      "Epoch: 109, Loss: 0.0718015655875206\n",
      "Epoch: 110, Loss: 0.06440471112728119\n",
      "Epoch: 111, Loss: 0.03771703690290451\n",
      "Epoch: 112, Loss: 0.03063078597187996\n",
      "Epoch: 113, Loss: 0.0763418972492218\n",
      "Epoch: 114, Loss: 0.05614795908331871\n",
      "Epoch: 115, Loss: 0.03829057887196541\n",
      "Epoch: 116, Loss: 0.06422044336795807\n",
      "Epoch: 117, Loss: 0.04974893853068352\n",
      "Epoch: 118, Loss: 0.06595488637685776\n",
      "Epoch: 119, Loss: 0.05320483446121216\n",
      "Epoch: 120, Loss: 0.03280309960246086\n",
      "Epoch: 121, Loss: 0.05421070381999016\n",
      "Epoch: 122, Loss: 0.06078246608376503\n",
      "Epoch: 123, Loss: 0.06376198679208755\n",
      "Epoch: 124, Loss: 0.029940513893961906\n",
      "Epoch: 125, Loss: 0.035749178379774094\n",
      "Epoch: 126, Loss: 0.045891232788562775\n",
      "Epoch: 127, Loss: 0.02917201817035675\n",
      "Epoch: 128, Loss: 0.06184658408164978\n",
      "Epoch: 129, Loss: 0.060140036046504974\n",
      "Epoch: 130, Loss: 0.033128704875707626\n",
      "Epoch: 131, Loss: 0.05829036980867386\n",
      "Epoch: 132, Loss: 0.06212039291858673\n",
      "Epoch: 133, Loss: 0.023082880303263664\n",
      "Epoch: 134, Loss: 0.06388375908136368\n",
      "Epoch: 135, Loss: 0.05967725068330765\n",
      "Epoch: 136, Loss: 0.04188757389783859\n",
      "Epoch: 137, Loss: 0.03712741285562515\n",
      "Epoch: 138, Loss: 0.05381195247173309\n",
      "Epoch: 139, Loss: 0.0339575931429863\n",
      "Epoch: 140, Loss: 0.058915428817272186\n",
      "Epoch: 141, Loss: 0.05521881952881813\n",
      "Epoch: 142, Loss: 0.04465140774846077\n",
      "Epoch: 143, Loss: 0.03350351005792618\n",
      "Epoch: 144, Loss: 0.05223226547241211\n",
      "Epoch: 145, Loss: 0.05042435973882675\n",
      "Epoch: 146, Loss: 0.0654832273721695\n",
      "Epoch: 147, Loss: 0.02635015919804573\n",
      "Epoch: 148, Loss: 0.06636971980333328\n",
      "Epoch: 149, Loss: 0.052625492215156555\n",
      "Epoch: 150, Loss: 0.055622950196266174\n",
      "Epoch: 151, Loss: 0.04524906352162361\n",
      "Epoch: 152, Loss: 0.052978139370679855\n",
      "Epoch: 153, Loss: 0.046619582921266556\n",
      "Epoch: 154, Loss: 0.0504811592400074\n",
      "Epoch: 155, Loss: 0.0573701448738575\n",
      "Epoch: 156, Loss: 0.026372341439127922\n",
      "Epoch: 157, Loss: 0.04701971262693405\n",
      "Epoch: 158, Loss: 0.05408145859837532\n",
      "Epoch: 159, Loss: 0.026576923206448555\n",
      "Epoch: 160, Loss: 0.02167399972677231\n",
      "Epoch: 161, Loss: 0.028957625851035118\n",
      "Epoch: 162, Loss: 0.04161163419485092\n",
      "Epoch: 163, Loss: 0.061604373157024384\n",
      "Epoch: 164, Loss: 0.0570332333445549\n",
      "Epoch: 165, Loss: 0.02138402871787548\n",
      "Epoch: 166, Loss: 0.04087159037590027\n",
      "Epoch: 167, Loss: 0.05391427502036095\n",
      "Epoch: 168, Loss: 0.044864755123853683\n",
      "Epoch: 169, Loss: 0.0564066506922245\n",
      "Epoch: 170, Loss: 0.042000070214271545\n",
      "Epoch: 171, Loss: 0.059068284928798676\n",
      "Epoch: 172, Loss: 0.020448051393032074\n",
      "Epoch: 173, Loss: 0.039133913815021515\n",
      "Epoch: 174, Loss: 0.026510387659072876\n",
      "Epoch: 175, Loss: 0.03504394367337227\n",
      "Epoch: 176, Loss: 0.04717262089252472\n",
      "Epoch: 177, Loss: 0.02652323991060257\n",
      "Epoch: 178, Loss: 0.04637372866272926\n",
      "Epoch: 179, Loss: 0.05540486425161362\n",
      "Epoch: 180, Loss: 0.02844778075814247\n",
      "Epoch: 181, Loss: 0.04218151047825813\n",
      "Epoch: 182, Loss: 0.0439157709479332\n",
      "Epoch: 183, Loss: 0.016905175521969795\n",
      "Epoch: 184, Loss: 0.043447110801935196\n",
      "Epoch: 185, Loss: 0.04983189329504967\n",
      "Epoch: 186, Loss: 0.041065819561481476\n",
      "Epoch: 187, Loss: 0.020741192623972893\n",
      "Epoch: 188, Loss: 0.04299168288707733\n",
      "Epoch: 189, Loss: 0.03751010820269585\n",
      "Epoch: 190, Loss: 0.051529426127672195\n",
      "Epoch: 191, Loss: 0.03468406945466995\n",
      "Epoch: 192, Loss: 0.04894857108592987\n",
      "Epoch: 193, Loss: 0.05580746755003929\n",
      "Epoch: 194, Loss: 0.04949422925710678\n",
      "Epoch: 195, Loss: 0.05004764348268509\n",
      "Epoch: 196, Loss: 0.03853977471590042\n",
      "Epoch: 197, Loss: 0.04244463890790939\n",
      "Epoch: 198, Loss: 0.05513523146510124\n",
      "Epoch: 199, Loss: 0.04763679578900337\n",
      "Epoch: 200, Loss: 0.04695160314440727\n",
      "Epoch: 201, Loss: 0.0488320030272007\n",
      "Epoch: 202, Loss: 0.046287454664707184\n",
      "Epoch: 203, Loss: 0.020711122080683708\n",
      "Epoch: 204, Loss: 0.04049203544855118\n",
      "Epoch: 205, Loss: 0.040285319089889526\n",
      "Epoch: 206, Loss: 0.05048119276762009\n",
      "Epoch: 207, Loss: 0.06349993497133255\n",
      "Epoch: 208, Loss: 0.0465141236782074\n",
      "Epoch: 209, Loss: 0.03668929636478424\n",
      "Epoch: 210, Loss: 0.04793243855237961\n",
      "Epoch: 211, Loss: 0.03575742244720459\n",
      "Epoch: 212, Loss: 0.03739871084690094\n",
      "Epoch: 213, Loss: 0.05197016894817352\n",
      "Epoch: 214, Loss: 0.03957591578364372\n",
      "Epoch: 215, Loss: 0.032371364533901215\n",
      "Epoch: 216, Loss: 0.05502019822597504\n",
      "Epoch: 217, Loss: 0.042650192975997925\n",
      "Epoch: 218, Loss: 0.0220665130764246\n",
      "Epoch: 219, Loss: 0.045451775193214417\n",
      "Epoch: 220, Loss: 0.04414895549416542\n",
      "Epoch: 221, Loss: 0.02398066222667694\n",
      "Epoch: 222, Loss: 0.049853499978780746\n",
      "Epoch: 223, Loss: 0.045048780739307404\n",
      "Epoch: 224, Loss: 0.04876119643449783\n",
      "Epoch: 225, Loss: 0.03850593790411949\n",
      "Epoch: 226, Loss: 0.019089868292212486\n",
      "Epoch: 227, Loss: 0.03154728561639786\n",
      "Epoch: 228, Loss: 0.06223192811012268\n",
      "Epoch: 229, Loss: 0.02640390209853649\n",
      "Epoch: 230, Loss: 0.03498544543981552\n",
      "Epoch: 231, Loss: 0.05040930584073067\n",
      "Epoch: 232, Loss: 0.049857981503009796\n",
      "Epoch: 233, Loss: 0.03547107055783272\n",
      "Epoch: 234, Loss: 0.03317999467253685\n",
      "Epoch: 235, Loss: 0.04219247028231621\n",
      "Epoch: 236, Loss: 0.016444796696305275\n",
      "Epoch: 237, Loss: 0.01676776260137558\n",
      "Epoch: 238, Loss: 0.04014945402741432\n",
      "Epoch: 239, Loss: 0.03960738331079483\n",
      "Epoch: 240, Loss: 0.04302601516246796\n",
      "Epoch: 241, Loss: 0.04198037087917328\n",
      "Epoch: 242, Loss: 0.01792605035007\n",
      "Epoch: 243, Loss: 0.05138556659221649\n",
      "Epoch: 244, Loss: 0.053515367209911346\n",
      "Epoch: 245, Loss: 0.032757509499788284\n",
      "Epoch: 246, Loss: 0.041290443390607834\n",
      "Epoch: 247, Loss: 0.03467502444982529\n",
      "Epoch: 248, Loss: 0.041908878833055496\n",
      "Epoch: 249, Loss: 0.031682338565588\n",
      "Epoch: 250, Loss: 0.050495922565460205\n",
      "Epoch: 251, Loss: 0.017671164125204086\n",
      "Epoch: 252, Loss: 0.04356426000595093\n",
      "Epoch: 253, Loss: 0.04809501767158508\n",
      "Epoch: 254, Loss: 0.03711561858654022\n",
      "Epoch: 255, Loss: 0.0417148731648922\n",
      "Epoch: 256, Loss: 0.04415678232908249\n",
      "Epoch: 257, Loss: 0.02585088275372982\n",
      "Epoch: 258, Loss: 0.031001299619674683\n",
      "Epoch: 259, Loss: 0.034819409251213074\n",
      "Epoch: 260, Loss: 0.06451500207185745\n",
      "Epoch: 261, Loss: 0.03241730108857155\n",
      "Epoch: 262, Loss: 0.049805887043476105\n",
      "Epoch: 263, Loss: 0.03520343452692032\n",
      "Epoch: 264, Loss: 0.04682653397321701\n",
      "Epoch: 265, Loss: 0.013420985080301762\n",
      "Epoch: 266, Loss: 0.041788000613451004\n",
      "Epoch: 267, Loss: 0.04918711632490158\n",
      "Epoch: 268, Loss: 0.050882015377283096\n",
      "Epoch: 269, Loss: 0.03460053354501724\n",
      "Epoch: 270, Loss: 0.03269478306174278\n",
      "Epoch: 271, Loss: 0.03794345632195473\n",
      "Epoch: 272, Loss: 0.015862513333559036\n",
      "Epoch: 273, Loss: 0.019630473107099533\n",
      "Epoch: 274, Loss: 0.03944084048271179\n",
      "Epoch: 275, Loss: 0.0436994768679142\n",
      "Epoch: 276, Loss: 0.0344112254679203\n",
      "Epoch: 277, Loss: 0.037427932024002075\n",
      "Epoch: 278, Loss: 0.03466780111193657\n",
      "Epoch: 279, Loss: 0.03507279232144356\n",
      "Epoch: 280, Loss: 0.013463139533996582\n",
      "Epoch: 281, Loss: 0.03121918998658657\n",
      "Epoch: 282, Loss: 0.03297560289502144\n",
      "Epoch: 283, Loss: 0.03879903256893158\n",
      "Epoch: 284, Loss: 0.03585459664463997\n",
      "Epoch: 285, Loss: 0.01907428540289402\n",
      "Epoch: 286, Loss: 0.03730534389615059\n",
      "Epoch: 287, Loss: 0.048471905291080475\n",
      "Epoch: 288, Loss: 0.03767023980617523\n",
      "Epoch: 289, Loss: 0.030219368636608124\n",
      "Epoch: 290, Loss: 0.040529049932956696\n",
      "Epoch: 291, Loss: 0.029270797967910767\n",
      "Epoch: 292, Loss: 0.027930058538913727\n",
      "Epoch: 293, Loss: 0.01397803332656622\n",
      "Epoch: 294, Loss: 0.03642655909061432\n",
      "Epoch: 295, Loss: 0.03997538983821869\n",
      "Epoch: 296, Loss: 0.04081934690475464\n",
      "Epoch: 297, Loss: 0.025032738223671913\n",
      "Epoch: 298, Loss: 0.01863737963140011\n",
      "Epoch: 299, Loss: 0.02014804258942604\n",
      "Epoch: 300, Loss: 0.03621833026409149\n",
      "Epoch: 301, Loss: 0.035888537764549255\n",
      "Epoch: 302, Loss: 0.0361102856695652\n",
      "Epoch: 303, Loss: 0.03449650853872299\n",
      "Epoch: 304, Loss: 0.03444448485970497\n",
      "Epoch: 305, Loss: 0.03435672074556351\n",
      "Epoch: 306, Loss: 0.03126516938209534\n",
      "Epoch: 307, Loss: 0.03645462915301323\n",
      "Epoch: 308, Loss: 0.034452907741069794\n",
      "Epoch: 309, Loss: 0.04654513671994209\n",
      "Epoch: 310, Loss: 0.036080241203308105\n",
      "Epoch: 311, Loss: 0.03186752274632454\n",
      "Epoch: 312, Loss: 0.016412200406193733\n",
      "Epoch: 313, Loss: 0.013740034773945808\n",
      "Epoch: 314, Loss: 0.03852735087275505\n",
      "Epoch: 315, Loss: 0.011846416629850864\n",
      "Epoch: 316, Loss: 0.024976687505841255\n",
      "Epoch: 317, Loss: 0.018754031509160995\n",
      "Epoch: 318, Loss: 0.03316148743033409\n",
      "Epoch: 319, Loss: 0.03598436713218689\n",
      "Epoch: 320, Loss: 0.03770536929368973\n",
      "Epoch: 321, Loss: 0.03828667849302292\n",
      "Epoch: 322, Loss: 0.01662030629813671\n",
      "Epoch: 323, Loss: 0.034544650465250015\n",
      "Epoch: 324, Loss: 0.043752238154411316\n",
      "Epoch: 325, Loss: 0.03590605407953262\n",
      "Epoch: 326, Loss: 0.03790110722184181\n",
      "Epoch: 327, Loss: 0.036775436252355576\n",
      "Epoch: 328, Loss: 0.03712396323680878\n",
      "Epoch: 329, Loss: 0.036048270761966705\n",
      "Epoch: 330, Loss: 0.030017344281077385\n",
      "Epoch: 331, Loss: 0.03433983772993088\n",
      "Epoch: 332, Loss: 0.03165329620242119\n",
      "Epoch: 333, Loss: 0.02871597558259964\n",
      "Epoch: 334, Loss: 0.03992420807480812\n",
      "Epoch: 335, Loss: 0.05934832617640495\n",
      "Epoch: 336, Loss: 0.0262248907238245\n",
      "Epoch: 337, Loss: 0.030744772404432297\n",
      "Epoch: 338, Loss: 0.027996214106678963\n",
      "Epoch: 339, Loss: 0.030159955844283104\n",
      "Epoch: 340, Loss: 0.03629278764128685\n",
      "Epoch: 341, Loss: 0.031628161668777466\n",
      "Epoch: 342, Loss: 0.03293728828430176\n",
      "Epoch: 343, Loss: 0.03641023859381676\n",
      "Epoch: 344, Loss: 0.012099187821149826\n",
      "Epoch: 345, Loss: 0.03419765457510948\n",
      "Epoch: 346, Loss: 0.013570078648626804\n",
      "Epoch: 347, Loss: 0.03194127231836319\n",
      "Epoch: 348, Loss: 0.030297037214040756\n",
      "Epoch: 349, Loss: 0.040423549711704254\n",
      "Epoch: 350, Loss: 0.03387216851115227\n",
      "Epoch: 351, Loss: 0.039396677166223526\n",
      "Epoch: 352, Loss: 0.040559034794569016\n",
      "Epoch: 353, Loss: 0.029209494590759277\n",
      "Epoch: 354, Loss: 0.03648543357849121\n",
      "Epoch: 355, Loss: 0.029809264466166496\n",
      "Epoch: 356, Loss: 0.04138367995619774\n",
      "Epoch: 357, Loss: 0.032683636993169785\n",
      "Epoch: 358, Loss: 0.03740869462490082\n",
      "Epoch: 359, Loss: 0.03642914444208145\n",
      "Epoch: 360, Loss: 0.03648476302623749\n",
      "Epoch: 361, Loss: 0.03388223052024841\n",
      "Epoch: 362, Loss: 0.03704303875565529\n",
      "Epoch: 363, Loss: 0.0319366529583931\n",
      "Epoch: 364, Loss: 0.043105270713567734\n",
      "Epoch: 365, Loss: 0.031438399106264114\n",
      "Epoch: 366, Loss: 0.03167382627725601\n",
      "Epoch: 367, Loss: 0.034822192043066025\n",
      "Epoch: 368, Loss: 0.0234842412173748\n",
      "Epoch: 369, Loss: 0.03701592981815338\n",
      "Epoch: 370, Loss: 0.018439380452036858\n",
      "Epoch: 371, Loss: 0.02682768553495407\n",
      "Epoch: 372, Loss: 0.032215580344200134\n",
      "Epoch: 373, Loss: 0.0328548401594162\n",
      "Epoch: 374, Loss: 0.02820463478565216\n",
      "Epoch: 375, Loss: 0.018655119463801384\n",
      "Epoch: 376, Loss: 0.03279958665370941\n",
      "Epoch: 377, Loss: 0.029222611337900162\n",
      "Epoch: 378, Loss: 0.012720318511128426\n",
      "Epoch: 379, Loss: 0.028930839151144028\n",
      "Epoch: 380, Loss: 0.04243091866374016\n",
      "Epoch: 381, Loss: 0.03729339316487312\n",
      "Epoch: 382, Loss: 0.028088413178920746\n",
      "Epoch: 383, Loss: 0.03102770447731018\n",
      "Epoch: 384, Loss: 0.03328895568847656\n",
      "Epoch: 385, Loss: 0.02137484960258007\n",
      "Epoch: 386, Loss: 0.03822673484683037\n",
      "Epoch: 387, Loss: 0.03103909082710743\n",
      "Epoch: 388, Loss: 0.034630171954631805\n",
      "Epoch: 389, Loss: 0.033689700067043304\n",
      "Epoch: 390, Loss: 0.024968085810542107\n",
      "Epoch: 391, Loss: 0.03826308995485306\n",
      "Epoch: 392, Loss: 0.040242165327072144\n",
      "Epoch: 393, Loss: 0.034495919942855835\n",
      "Epoch: 394, Loss: 0.034949418157339096\n",
      "Epoch: 395, Loss: 0.03421058878302574\n",
      "Epoch: 396, Loss: 0.03339356184005737\n",
      "Epoch: 397, Loss: 0.028507061302661896\n",
      "Epoch: 398, Loss: 0.03028400056064129\n",
      "Epoch: 399, Loss: 0.03640886768698692\n",
      "Epoch: 400, Loss: 0.031825534999370575\n",
      "Epoch: 401, Loss: 0.03654482215642929\n",
      "Epoch: 402, Loss: 0.010579417459666729\n",
      "Epoch: 403, Loss: 0.024917354807257652\n",
      "Epoch: 404, Loss: 0.019305886700749397\n",
      "Epoch: 405, Loss: 0.02877684496343136\n",
      "Epoch: 406, Loss: 0.028564268723130226\n",
      "Epoch: 407, Loss: 0.04198668152093887\n",
      "Epoch: 408, Loss: 0.029439013451337814\n",
      "Epoch: 409, Loss: 0.024929571896791458\n",
      "Epoch: 410, Loss: 0.027372952550649643\n",
      "Epoch: 411, Loss: 0.028000948950648308\n",
      "Epoch: 412, Loss: 0.01442946121096611\n",
      "Epoch: 413, Loss: 0.030753465369343758\n",
      "Epoch: 414, Loss: 0.028080835938453674\n",
      "Epoch: 415, Loss: 0.01045227237045765\n",
      "Epoch: 416, Loss: 0.022067364305257797\n",
      "Epoch: 417, Loss: 0.016843192279338837\n",
      "Epoch: 418, Loss: 0.03830914571881294\n",
      "Epoch: 419, Loss: 0.033138200640678406\n",
      "Epoch: 420, Loss: 0.010110988281667233\n",
      "Epoch: 421, Loss: 0.01549001969397068\n",
      "Epoch: 422, Loss: 0.033009208738803864\n",
      "Epoch: 423, Loss: 0.028592677786946297\n",
      "Epoch: 424, Loss: 0.03503210470080376\n",
      "Epoch: 425, Loss: 0.03853414207696915\n",
      "Epoch: 426, Loss: 0.03059287928044796\n",
      "Epoch: 427, Loss: 0.03094831109046936\n",
      "Epoch: 428, Loss: 0.026407461613416672\n",
      "Epoch: 429, Loss: 0.01652143895626068\n",
      "Epoch: 430, Loss: 0.017119374126195908\n",
      "Epoch: 431, Loss: 0.02802124060690403\n",
      "Epoch: 432, Loss: 0.039942216128110886\n",
      "Epoch: 433, Loss: 0.012615012004971504\n",
      "Epoch: 434, Loss: 0.026437776163220406\n",
      "Epoch: 435, Loss: 0.028698014095425606\n",
      "Epoch: 436, Loss: 0.029108069837093353\n",
      "Epoch: 437, Loss: 0.028743671253323555\n",
      "Epoch: 438, Loss: 0.02775353193283081\n",
      "Epoch: 439, Loss: 0.02117305062711239\n",
      "Epoch: 440, Loss: 0.019290680065751076\n",
      "Epoch: 441, Loss: 0.018472017720341682\n",
      "Epoch: 442, Loss: 0.03614123538136482\n",
      "Epoch: 443, Loss: 0.013049988076090813\n",
      "Epoch: 444, Loss: 0.035558585077524185\n",
      "Epoch: 445, Loss: 0.04111062362790108\n",
      "Epoch: 446, Loss: 0.023392394185066223\n",
      "Epoch: 447, Loss: 0.012773470021784306\n",
      "Epoch: 448, Loss: 0.03213821351528168\n",
      "Epoch: 449, Loss: 0.02464386820793152\n",
      "Epoch: 450, Loss: 0.010787037201225758\n",
      "Epoch: 451, Loss: 0.028206070885062218\n",
      "Epoch: 452, Loss: 0.027385465800762177\n",
      "Epoch: 453, Loss: 0.015460364520549774\n",
      "Epoch: 454, Loss: 0.0333687998354435\n",
      "Epoch: 455, Loss: 0.022532658651471138\n",
      "Epoch: 456, Loss: 0.02813401259481907\n",
      "Epoch: 457, Loss: 0.013878189958631992\n",
      "Epoch: 458, Loss: 0.039139535278081894\n",
      "Epoch: 459, Loss: 0.03730805963277817\n",
      "Epoch: 460, Loss: 0.026642218232154846\n",
      "Epoch: 461, Loss: 0.030749263241887093\n",
      "Epoch: 462, Loss: 0.028273437172174454\n",
      "Epoch: 463, Loss: 0.03467230126261711\n",
      "Epoch: 464, Loss: 0.02806628867983818\n",
      "Epoch: 465, Loss: 0.031594641506671906\n",
      "Epoch: 466, Loss: 0.0292269978672266\n",
      "Epoch: 467, Loss: 0.010042713023722172\n",
      "Epoch: 468, Loss: 0.026481442153453827\n",
      "Epoch: 469, Loss: 0.02319704182446003\n",
      "Epoch: 470, Loss: 0.026673540472984314\n",
      "Epoch: 471, Loss: 0.024071654304862022\n",
      "Epoch: 472, Loss: 0.025258434936404228\n",
      "Epoch: 473, Loss: 0.025673959404230118\n",
      "Epoch: 474, Loss: 0.022483807057142258\n",
      "Epoch: 475, Loss: 0.025168171152472496\n",
      "Epoch: 476, Loss: 0.03609400987625122\n",
      "Epoch: 477, Loss: 0.025344308465719223\n",
      "Epoch: 478, Loss: 0.02675454318523407\n",
      "Epoch: 479, Loss: 0.02685939148068428\n",
      "Epoch: 480, Loss: 0.020106632262468338\n",
      "Epoch: 481, Loss: 0.009027515538036823\n",
      "Epoch: 482, Loss: 0.0157926045358181\n",
      "Epoch: 483, Loss: 0.031928256154060364\n",
      "Epoch: 484, Loss: 0.03761418163776398\n",
      "Epoch: 485, Loss: 0.023654866963624954\n",
      "Epoch: 486, Loss: 0.026484962552785873\n",
      "Epoch: 487, Loss: 0.03244498372077942\n",
      "Epoch: 488, Loss: 0.013542179949581623\n",
      "Epoch: 489, Loss: 0.014026738703250885\n",
      "Epoch: 490, Loss: 0.03580872341990471\n",
      "Epoch: 491, Loss: 0.03168533369898796\n",
      "Epoch: 492, Loss: 0.02599954605102539\n",
      "Epoch: 493, Loss: 0.029235949739813805\n",
      "Epoch: 494, Loss: 0.029090946540236473\n",
      "Epoch: 495, Loss: 0.02623124048113823\n",
      "Epoch: 496, Loss: 0.01450271438807249\n",
      "Epoch: 497, Loss: 0.025801604613661766\n",
      "Epoch: 498, Loss: 0.011005845852196217\n",
      "Epoch: 499, Loss: 0.02616243250668049\n",
      "Epoch: 500, Loss: 0.014870229177176952\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "num_epochs = 500\n",
    "model = model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, targets) in enumerate(train_dataloader):\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {losses.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
