{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download labeling from GitHub - https://github.com/tzutalin/labelImg\n",
    "\n",
    "\n",
    "`!pip install pyqt5`\n",
    "\n",
    "`!pip install lxml`\n",
    "\n",
    "\n",
    "Installation guide - https://github.com/heartexlabs/labelImg#installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command in the terminal\n",
    "\n",
    "`pyrcc5 -o libs/resources.py resources.qrc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection.retinanet import RetinaNet_ResNet50_FPN_Weights\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Number of classes including background\n",
    "num_classes = 91 \n",
    "\n",
    "# Load a pre-trained model\n",
    "model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True, num_classes=num_classes)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Continue with your code...(Origional numbers)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "\n",
    "class YOLODataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform if transform else transforms.ToTensor()\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root_dir, \"images\"))))\n",
    "        self.labels = list(sorted(os.listdir(os.path.join(root_dir, \"labels\"))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, \"images\", self.imgs[idx])\n",
    "        label_path = os.path.join(self.root_dir, \"labels\", self.labels[idx])\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_width, img_height = img.size\n",
    "\n",
    "        # Apply transformation after getting original size\n",
    "        img = self.transform(img)\n",
    "\n",
    "        # Read YOLO label file\n",
    "        with open(label_path, \"r\") as file:\n",
    "            lines = file.read().splitlines()\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for line in lines:\n",
    "            class_id, x_center, y_center, width, height = map(float, line.split())\n",
    "            labels.append(int(class_id))\n",
    "\n",
    "            x_min = img_width * (x_center - width / 2)\n",
    "            y_min = img_height * (y_center - height / 2)\n",
    "            x_max = img_width * (x_center + width / 2)\n",
    "            y_max = img_height * (y_center + height / 2)\n",
    "            boxes.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = torch.tensor(boxes, dtype=torch.float32)\n",
    "        target['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "# Define your own paths here\n",
    "train_dataset = YOLODataset(\"data/train set\")\n",
    "valid_dataset = YOLODataset(\"data/validation set\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "\n",
    "    return images, targets\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.5, weight_decay=0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.2300820350646973\n",
      "Epoch: 2, Loss: 1.003377914428711\n",
      "Epoch: 3, Loss: 0.7857272624969482\n",
      "Epoch: 4, Loss: 0.594941258430481\n",
      "Epoch: 5, Loss: 0.5054682493209839\n",
      "Epoch: 6, Loss: 0.47064507007598877\n",
      "Epoch: 7, Loss: 0.40548959374427795\n",
      "Epoch: 8, Loss: 0.41325682401657104\n",
      "Epoch: 9, Loss: 0.407090961933136\n",
      "Epoch: 10, Loss: 0.3572027087211609\n",
      "Epoch: 11, Loss: 0.3457500636577606\n",
      "Epoch: 12, Loss: 0.3764718174934387\n",
      "Epoch: 13, Loss: 0.3649718165397644\n",
      "Epoch: 14, Loss: 0.3403128385543823\n",
      "Epoch: 15, Loss: 0.31691306829452515\n",
      "Epoch: 16, Loss: 0.35058021545410156\n",
      "Epoch: 17, Loss: 0.37347838282585144\n",
      "Epoch: 18, Loss: 0.3164554238319397\n",
      "Epoch: 19, Loss: 0.3140256106853485\n",
      "Epoch: 20, Loss: 0.2953784465789795\n",
      "Epoch: 21, Loss: 0.30577096343040466\n",
      "Epoch: 22, Loss: 0.3276333212852478\n",
      "Epoch: 23, Loss: 0.2857816517353058\n",
      "Epoch: 24, Loss: 0.28307726979255676\n",
      "Epoch: 25, Loss: 0.2928995192050934\n",
      "Epoch: 26, Loss: 0.29061487317085266\n",
      "Epoch: 27, Loss: 0.3013363480567932\n",
      "Epoch: 28, Loss: 0.2860627770423889\n",
      "Epoch: 29, Loss: 0.27100926637649536\n",
      "Epoch: 30, Loss: 0.29217690229415894\n",
      "Epoch: 31, Loss: 0.3045564591884613\n",
      "Epoch: 32, Loss: 0.3021864891052246\n",
      "Epoch: 33, Loss: 0.27510783076286316\n",
      "Epoch: 34, Loss: 0.26576995849609375\n",
      "Epoch: 35, Loss: 0.2966923713684082\n",
      "Epoch: 36, Loss: 0.2481541782617569\n",
      "Epoch: 37, Loss: 0.2587888240814209\n",
      "Epoch: 38, Loss: 0.2452300786972046\n",
      "Epoch: 39, Loss: 0.29407963156700134\n",
      "Epoch: 40, Loss: 0.2803105413913727\n",
      "Epoch: 41, Loss: 0.26038217544555664\n",
      "Epoch: 42, Loss: 0.2530311644077301\n",
      "Epoch: 43, Loss: 0.24627986550331116\n",
      "Epoch: 44, Loss: 0.2875882089138031\n",
      "Epoch: 45, Loss: 0.2452434003353119\n",
      "Epoch: 46, Loss: 0.2732902765274048\n",
      "Epoch: 47, Loss: 0.27200907468795776\n",
      "Epoch: 48, Loss: 0.23177781701087952\n",
      "Epoch: 49, Loss: 0.2594203054904938\n",
      "Epoch: 50, Loss: 0.23649394512176514\n",
      "Epoch: 51, Loss: 0.2491365373134613\n",
      "Epoch: 52, Loss: 0.22705647349357605\n",
      "Epoch: 53, Loss: 0.26563119888305664\n",
      "Epoch: 54, Loss: 0.23769396543502808\n",
      "Epoch: 55, Loss: 0.2519029676914215\n",
      "Epoch: 56, Loss: 0.2432258129119873\n",
      "Epoch: 57, Loss: 0.2400020956993103\n",
      "Epoch: 58, Loss: 0.23340684175491333\n",
      "Epoch: 59, Loss: 0.2320193201303482\n",
      "Epoch: 60, Loss: 0.26384690403938293\n",
      "Epoch: 61, Loss: 0.226791113615036\n",
      "Epoch: 62, Loss: 0.271966814994812\n",
      "Epoch: 63, Loss: 0.24377524852752686\n",
      "Epoch: 64, Loss: 0.2699497640132904\n",
      "Epoch: 65, Loss: 0.22051376104354858\n",
      "Epoch: 66, Loss: 0.23130495846271515\n",
      "Epoch: 67, Loss: 0.267548143863678\n",
      "Epoch: 68, Loss: 0.26633766293525696\n",
      "Epoch: 69, Loss: 0.21679967641830444\n",
      "Epoch: 70, Loss: 0.21584957838058472\n",
      "Epoch: 71, Loss: 0.21045857667922974\n",
      "Epoch: 72, Loss: 0.2669297456741333\n",
      "Epoch: 73, Loss: 0.22792363166809082\n",
      "Epoch: 74, Loss: 0.21642199158668518\n",
      "Epoch: 75, Loss: 0.2640072703361511\n",
      "Epoch: 76, Loss: 0.2498452514410019\n",
      "Epoch: 77, Loss: 0.22263303399085999\n",
      "Epoch: 78, Loss: 0.257976770401001\n",
      "Epoch: 79, Loss: 0.23236802220344543\n",
      "Epoch: 80, Loss: 0.24710136651992798\n",
      "Epoch: 81, Loss: 0.2078673541545868\n",
      "Epoch: 82, Loss: 0.25231999158859253\n",
      "Epoch: 83, Loss: 0.229549378156662\n",
      "Epoch: 84, Loss: 0.22852179408073425\n",
      "Epoch: 85, Loss: 0.21920016407966614\n",
      "Epoch: 86, Loss: 0.24333462119102478\n",
      "Epoch: 87, Loss: 0.24685585498809814\n",
      "Epoch: 88, Loss: 0.2415010780096054\n",
      "Epoch: 89, Loss: 0.258112370967865\n",
      "Epoch: 90, Loss: 0.18915006518363953\n",
      "Epoch: 91, Loss: 0.20523472130298615\n",
      "Epoch: 92, Loss: 0.24015304446220398\n",
      "Epoch: 93, Loss: 0.1846296489238739\n",
      "Epoch: 94, Loss: 0.20751361548900604\n",
      "Epoch: 95, Loss: 0.22256135940551758\n",
      "Epoch: 96, Loss: 0.19873636960983276\n",
      "Epoch: 97, Loss: 0.2354908585548401\n",
      "Epoch: 98, Loss: 0.1926511973142624\n",
      "Epoch: 99, Loss: 0.19681398570537567\n",
      "Epoch: 100, Loss: 0.1843940019607544\n",
      "Epoch: 101, Loss: 0.17854592204093933\n",
      "Epoch: 102, Loss: 0.20307303965091705\n",
      "Epoch: 103, Loss: 0.18181583285331726\n",
      "Epoch: 104, Loss: 0.20631885528564453\n",
      "Epoch: 105, Loss: 0.23423048853874207\n",
      "Epoch: 106, Loss: 0.22657369077205658\n",
      "Epoch: 107, Loss: 0.1730029582977295\n",
      "Epoch: 108, Loss: 0.23322013020515442\n",
      "Epoch: 109, Loss: 0.2056475728750229\n",
      "Epoch: 110, Loss: 0.223158597946167\n",
      "Epoch: 111, Loss: 0.22857661545276642\n",
      "Epoch: 112, Loss: 0.1945226490497589\n",
      "Epoch: 113, Loss: 0.22026845812797546\n",
      "Epoch: 114, Loss: 0.1972683221101761\n",
      "Epoch: 115, Loss: 0.24980759620666504\n",
      "Epoch: 116, Loss: 0.1679757833480835\n",
      "Epoch: 117, Loss: 0.17319142818450928\n",
      "Epoch: 118, Loss: 0.22453704476356506\n",
      "Epoch: 119, Loss: 0.18246078491210938\n",
      "Epoch: 120, Loss: 0.22326374053955078\n",
      "Epoch: 121, Loss: 0.19851163029670715\n",
      "Epoch: 122, Loss: 0.24638381600379944\n",
      "Epoch: 123, Loss: 0.19835662841796875\n",
      "Epoch: 124, Loss: 0.22084319591522217\n",
      "Epoch: 125, Loss: 0.2141043096780777\n",
      "Epoch: 126, Loss: 0.21169808506965637\n",
      "Epoch: 127, Loss: 0.24602529406547546\n",
      "Epoch: 128, Loss: 0.19119323790073395\n",
      "Epoch: 129, Loss: 0.1957242488861084\n",
      "Epoch: 130, Loss: 0.1674577295780182\n",
      "Epoch: 131, Loss: 0.21803578734397888\n",
      "Epoch: 132, Loss: 0.16642700135707855\n",
      "Epoch: 133, Loss: 0.18917439877986908\n",
      "Epoch: 134, Loss: 0.20633065700531006\n",
      "Epoch: 135, Loss: 0.19323594868183136\n",
      "Epoch: 136, Loss: 0.1640668511390686\n",
      "Epoch: 137, Loss: 0.16331282258033752\n",
      "Epoch: 138, Loss: 0.21521784365177155\n",
      "Epoch: 139, Loss: 0.2217419445514679\n",
      "Epoch: 140, Loss: 0.18656785786151886\n",
      "Epoch: 141, Loss: 0.16155996918678284\n",
      "Epoch: 142, Loss: 0.18584324419498444\n",
      "Epoch: 143, Loss: 0.19045880436897278\n",
      "Epoch: 144, Loss: 0.16003304719924927\n",
      "Epoch: 145, Loss: 0.18479931354522705\n",
      "Epoch: 146, Loss: 0.1724817156791687\n",
      "Epoch: 147, Loss: 0.1526535004377365\n",
      "Epoch: 148, Loss: 0.17636124789714813\n",
      "Epoch: 149, Loss: 0.18090064823627472\n",
      "Epoch: 150, Loss: 0.19901734590530396\n",
      "Epoch: 151, Loss: 0.18286284804344177\n",
      "Epoch: 152, Loss: 0.17066629230976105\n",
      "Epoch: 153, Loss: 0.21756359934806824\n",
      "Epoch: 154, Loss: 0.18690460920333862\n",
      "Epoch: 155, Loss: 0.15552566945552826\n",
      "Epoch: 156, Loss: 0.17347532510757446\n",
      "Epoch: 157, Loss: 0.1688918173313141\n",
      "Epoch: 158, Loss: 0.14759519696235657\n",
      "Epoch: 159, Loss: 0.1988150179386139\n",
      "Epoch: 160, Loss: 0.1463012397289276\n",
      "Epoch: 161, Loss: 0.20703303813934326\n",
      "Epoch: 162, Loss: 0.1977359652519226\n",
      "Epoch: 163, Loss: 0.1712965965270996\n",
      "Epoch: 164, Loss: 0.1707681566476822\n",
      "Epoch: 165, Loss: 0.17875204980373383\n",
      "Epoch: 166, Loss: 0.19142791628837585\n",
      "Epoch: 167, Loss: 0.20486706495285034\n",
      "Epoch: 168, Loss: 0.20438817143440247\n",
      "Epoch: 169, Loss: 0.17526784539222717\n",
      "Epoch: 170, Loss: 0.17480362951755524\n",
      "Epoch: 171, Loss: 0.19505903124809265\n",
      "Epoch: 172, Loss: 0.16499340534210205\n",
      "Epoch: 173, Loss: 0.16440001130104065\n",
      "Epoch: 174, Loss: 0.1815473437309265\n",
      "Epoch: 175, Loss: 0.21136994659900665\n",
      "Epoch: 176, Loss: 0.17563319206237793\n",
      "Epoch: 177, Loss: 0.186690092086792\n",
      "Epoch: 178, Loss: 0.18053053319454193\n",
      "Epoch: 179, Loss: 0.1801408976316452\n",
      "Epoch: 180, Loss: 0.1664302796125412\n",
      "Epoch: 181, Loss: 0.1659395545721054\n",
      "Epoch: 182, Loss: 0.20963267982006073\n",
      "Epoch: 183, Loss: 0.2304333597421646\n",
      "Epoch: 184, Loss: 0.17367205023765564\n",
      "Epoch: 185, Loss: 0.17151975631713867\n",
      "Epoch: 186, Loss: 0.16118492186069489\n",
      "Epoch: 187, Loss: 0.16450557112693787\n",
      "Epoch: 188, Loss: 0.1767822504043579\n",
      "Epoch: 189, Loss: 0.18175143003463745\n",
      "Epoch: 190, Loss: 0.20794157683849335\n",
      "Epoch: 191, Loss: 0.19785627722740173\n",
      "Epoch: 192, Loss: 0.18977828323841095\n",
      "Epoch: 193, Loss: 0.1696687936782837\n",
      "Epoch: 194, Loss: 0.14319166541099548\n",
      "Epoch: 195, Loss: 0.19655677676200867\n",
      "Epoch: 196, Loss: 0.19617383182048798\n",
      "Epoch: 197, Loss: 0.18860295414924622\n",
      "Epoch: 198, Loss: 0.17018599808216095\n",
      "Epoch: 199, Loss: 0.13377268612384796\n",
      "Epoch: 200, Loss: 0.1950887143611908\n",
      "Epoch: 201, Loss: 0.13263536989688873\n",
      "Epoch: 202, Loss: 0.16934828460216522\n",
      "Epoch: 203, Loss: 0.14027076959609985\n",
      "Epoch: 204, Loss: 0.17505957186222076\n",
      "Epoch: 205, Loss: 0.16718296706676483\n",
      "Epoch: 206, Loss: 0.18658800423145294\n",
      "Epoch: 207, Loss: 0.13078725337982178\n",
      "Epoch: 208, Loss: 0.1681252121925354\n",
      "Epoch: 209, Loss: 0.15691345930099487\n",
      "Epoch: 210, Loss: 0.1293441206216812\n",
      "Epoch: 211, Loss: 0.1595558375120163\n",
      "Epoch: 212, Loss: 0.18532700836658478\n",
      "Epoch: 213, Loss: 0.16569605469703674\n",
      "Epoch: 214, Loss: 0.1369854211807251\n",
      "Epoch: 215, Loss: 0.17294824123382568\n",
      "Epoch: 216, Loss: 0.17059308290481567\n",
      "Epoch: 217, Loss: 0.12661579251289368\n",
      "Epoch: 218, Loss: 0.12580935657024384\n",
      "Epoch: 219, Loss: 0.15783768892288208\n",
      "Epoch: 220, Loss: 0.16787712275981903\n",
      "Epoch: 221, Loss: 0.1697618067264557\n",
      "Epoch: 222, Loss: 0.22397714853286743\n",
      "Epoch: 223, Loss: 0.1901283711194992\n",
      "Epoch: 224, Loss: 0.22165068984031677\n",
      "Epoch: 225, Loss: 0.22058582305908203\n",
      "Epoch: 226, Loss: 0.16831237077713013\n",
      "Epoch: 227, Loss: 0.2191818654537201\n",
      "Epoch: 228, Loss: 0.1560320109128952\n",
      "Epoch: 229, Loss: 0.1675264984369278\n",
      "Epoch: 230, Loss: 0.13346846401691437\n",
      "Epoch: 231, Loss: 0.15297837555408478\n",
      "Epoch: 232, Loss: 0.1670021116733551\n",
      "Epoch: 233, Loss: 0.18108560144901276\n",
      "Epoch: 234, Loss: 0.16498056054115295\n",
      "Epoch: 235, Loss: 0.16190122067928314\n",
      "Epoch: 236, Loss: 0.1695149689912796\n",
      "Epoch: 237, Loss: 0.1660827398300171\n",
      "Epoch: 238, Loss: 0.13095256686210632\n",
      "Epoch: 239, Loss: 0.16891327500343323\n",
      "Epoch: 240, Loss: 0.12997402250766754\n",
      "Epoch: 241, Loss: 0.165233314037323\n",
      "Epoch: 242, Loss: 0.12946295738220215\n",
      "Epoch: 243, Loss: 0.17925412952899933\n",
      "Epoch: 244, Loss: 0.16028185188770294\n",
      "Epoch: 245, Loss: 0.18546494841575623\n",
      "Epoch: 246, Loss: 0.21615269780158997\n",
      "Epoch: 247, Loss: 0.16388775408267975\n",
      "Epoch: 248, Loss: 0.1635628044605255\n",
      "Epoch: 249, Loss: 0.18445855379104614\n",
      "Epoch: 250, Loss: 0.1281745582818985\n",
      "Epoch: 251, Loss: 0.18398705124855042\n",
      "Epoch: 252, Loss: 0.18351009488105774\n",
      "Epoch: 253, Loss: 0.16256392002105713\n",
      "Epoch: 254, Loss: 0.16217131912708282\n",
      "Epoch: 255, Loss: 0.19557474553585052\n",
      "Epoch: 256, Loss: 0.15800490975379944\n",
      "Epoch: 257, Loss: 0.1177590936422348\n",
      "Epoch: 258, Loss: 0.1491106152534485\n",
      "Epoch: 259, Loss: 0.12624353170394897\n",
      "Epoch: 260, Loss: 0.15799663960933685\n",
      "Epoch: 261, Loss: 0.1486559808254242\n",
      "Epoch: 262, Loss: 0.14835628867149353\n",
      "Epoch: 263, Loss: 0.11558317393064499\n",
      "Epoch: 264, Loss: 0.1583940088748932\n",
      "Epoch: 265, Loss: 0.19394972920417786\n",
      "Epoch: 266, Loss: 0.15612158179283142\n",
      "Epoch: 267, Loss: 0.17508018016815186\n",
      "Epoch: 268, Loss: 0.15764832496643066\n",
      "Epoch: 269, Loss: 0.2116066962480545\n",
      "Epoch: 270, Loss: 0.14912165701389313\n",
      "Epoch: 271, Loss: 0.12398137897253036\n",
      "Epoch: 272, Loss: 0.14856785535812378\n",
      "Epoch: 273, Loss: 0.14818152785301208\n",
      "Epoch: 274, Loss: 0.14650380611419678\n",
      "Epoch: 275, Loss: 0.1542445421218872\n",
      "Epoch: 276, Loss: 0.14617572724819183\n",
      "Epoch: 277, Loss: 0.14595352113246918\n",
      "Epoch: 278, Loss: 0.12234410643577576\n",
      "Epoch: 279, Loss: 0.1728391945362091\n",
      "Epoch: 280, Loss: 0.11255557090044022\n",
      "Epoch: 281, Loss: 0.16310259699821472\n",
      "Epoch: 282, Loss: 0.15145175158977509\n",
      "Epoch: 283, Loss: 0.11124593019485474\n",
      "Epoch: 284, Loss: 0.1452399045228958\n",
      "Epoch: 285, Loss: 0.16246828436851501\n",
      "Epoch: 286, Loss: 0.15407595038414001\n",
      "Epoch: 287, Loss: 0.19028684496879578\n",
      "Epoch: 288, Loss: 0.2077740877866745\n",
      "Epoch: 289, Loss: 0.15457570552825928\n",
      "Epoch: 290, Loss: 0.14584192633628845\n",
      "Epoch: 291, Loss: 0.17711636424064636\n",
      "Epoch: 292, Loss: 0.14538858830928802\n",
      "Epoch: 293, Loss: 0.2059430181980133\n",
      "Epoch: 294, Loss: 0.1103285551071167\n",
      "Epoch: 295, Loss: 0.11998017877340317\n",
      "Epoch: 296, Loss: 0.14359256625175476\n",
      "Epoch: 297, Loss: 0.16092240810394287\n",
      "Epoch: 298, Loss: 0.1694156974554062\n",
      "Epoch: 299, Loss: 0.15220001339912415\n",
      "Epoch: 300, Loss: 0.204459547996521\n",
      "Epoch: 301, Loss: 0.18783971667289734\n",
      "Epoch: 302, Loss: 0.16845643520355225\n",
      "Epoch: 303, Loss: 0.16800010204315186\n",
      "Epoch: 304, Loss: 0.10881009697914124\n",
      "Epoch: 305, Loss: 0.18725956976413727\n",
      "Epoch: 306, Loss: 0.1546933501958847\n",
      "Epoch: 307, Loss: 0.10783296823501587\n",
      "Epoch: 308, Loss: 0.18686404824256897\n",
      "Epoch: 309, Loss: 0.1175442785024643\n",
      "Epoch: 310, Loss: 0.20236435532569885\n",
      "Epoch: 311, Loss: 0.18604812026023865\n",
      "Epoch: 312, Loss: 0.1417289823293686\n",
      "Epoch: 313, Loss: 0.11709164083003998\n",
      "Epoch: 314, Loss: 0.15349557995796204\n",
      "Epoch: 315, Loss: 0.1854318380355835\n",
      "Epoch: 316, Loss: 0.15110057592391968\n",
      "Epoch: 317, Loss: 0.20079392194747925\n",
      "Epoch: 318, Loss: 0.1996995359659195\n",
      "Epoch: 319, Loss: 0.140928253531456\n",
      "Epoch: 320, Loss: 0.11627338081598282\n",
      "Epoch: 321, Loss: 0.10549572110176086\n",
      "Epoch: 322, Loss: 0.10484500229358673\n",
      "Epoch: 323, Loss: 0.16532723605632782\n",
      "Epoch: 324, Loss: 0.1579114943742752\n",
      "Epoch: 325, Loss: 0.14425352215766907\n",
      "Epoch: 326, Loss: 0.14302758872509003\n",
      "Epoch: 327, Loss: 0.15746432542800903\n",
      "Epoch: 328, Loss: 0.1401301622390747\n",
      "Epoch: 329, Loss: 0.14065024256706238\n",
      "Epoch: 330, Loss: 0.13970322906970978\n",
      "Epoch: 331, Loss: 0.1514332890510559\n",
      "Epoch: 332, Loss: 0.1639249473810196\n",
      "Epoch: 333, Loss: 0.14819268882274628\n",
      "Epoch: 334, Loss: 0.14785312116146088\n",
      "Epoch: 335, Loss: 0.15655621886253357\n",
      "Epoch: 336, Loss: 0.16315926611423492\n",
      "Epoch: 337, Loss: 0.18254370987415314\n",
      "Epoch: 338, Loss: 0.16262368857860565\n",
      "Epoch: 339, Loss: 0.10267031192779541\n",
      "Epoch: 340, Loss: 0.1483565866947174\n",
      "Epoch: 341, Loss: 0.18194599449634552\n",
      "Epoch: 342, Loss: 0.14991584420204163\n",
      "Epoch: 343, Loss: 0.16968664526939392\n",
      "Epoch: 344, Loss: 0.13914945721626282\n",
      "Epoch: 345, Loss: 0.13869231939315796\n",
      "Epoch: 346, Loss: 0.13837337493896484\n",
      "Epoch: 347, Loss: 0.1396896243095398\n",
      "Epoch: 348, Loss: 0.13809749484062195\n",
      "Epoch: 349, Loss: 0.10071521997451782\n",
      "Epoch: 350, Loss: 0.18080589175224304\n",
      "Epoch: 351, Loss: 0.1687558889389038\n",
      "Epoch: 352, Loss: 0.14696258306503296\n",
      "Epoch: 353, Loss: 0.1547519564628601\n",
      "Epoch: 354, Loss: 0.14845876395702362\n",
      "Epoch: 355, Loss: 0.148145392537117\n",
      "Epoch: 356, Loss: 0.13781504333019257\n",
      "Epoch: 357, Loss: 0.11065003275871277\n",
      "Epoch: 358, Loss: 0.11029694974422455\n",
      "Epoch: 359, Loss: 0.13637231290340424\n",
      "Epoch: 360, Loss: 0.09887126833200455\n",
      "Epoch: 361, Loss: 0.13512420654296875\n",
      "Epoch: 362, Loss: 0.1369023323059082\n",
      "Epoch: 363, Loss: 0.15367841720581055\n",
      "Epoch: 364, Loss: 0.14732104539871216\n",
      "Epoch: 365, Loss: 0.1364622861146927\n",
      "Epoch: 366, Loss: 0.15319612622261047\n",
      "Epoch: 367, Loss: 0.10908816754817963\n",
      "Epoch: 368, Loss: 0.15293017029762268\n",
      "Epoch: 369, Loss: 0.13414010405540466\n",
      "Epoch: 370, Loss: 0.13359719514846802\n",
      "Epoch: 371, Loss: 0.10816487669944763\n",
      "Epoch: 372, Loss: 0.09728133678436279\n",
      "Epoch: 373, Loss: 0.13559895753860474\n",
      "Epoch: 374, Loss: 0.14409831166267395\n",
      "Epoch: 375, Loss: 0.158020481467247\n",
      "Epoch: 376, Loss: 0.13557149469852448\n",
      "Epoch: 377, Loss: 0.14589063823223114\n",
      "Epoch: 378, Loss: 0.177179753780365\n",
      "Epoch: 379, Loss: 0.10759194940328598\n",
      "Epoch: 380, Loss: 0.14323696494102478\n",
      "Epoch: 381, Loss: 0.13510312139987946\n",
      "Epoch: 382, Loss: 0.1906762272119522\n",
      "Epoch: 383, Loss: 0.13459020853042603\n",
      "Epoch: 384, Loss: 0.18927575647830963\n",
      "Epoch: 385, Loss: 0.14268134534358978\n",
      "Epoch: 386, Loss: 0.15618138015270233\n",
      "Epoch: 387, Loss: 0.15583616495132446\n",
      "Epoch: 388, Loss: 0.15559250116348267\n",
      "Epoch: 389, Loss: 0.15113361179828644\n",
      "Epoch: 390, Loss: 0.1342230588197708\n",
      "Epoch: 391, Loss: 0.14435802400112152\n",
      "Epoch: 392, Loss: 0.15069560706615448\n",
      "Epoch: 393, Loss: 0.1751806139945984\n",
      "Epoch: 394, Loss: 0.14389319717884064\n",
      "Epoch: 395, Loss: 0.14287613332271576\n",
      "Epoch: 396, Loss: 0.14153099060058594\n",
      "Epoch: 397, Loss: 0.09502546489238739\n",
      "Epoch: 398, Loss: 0.13318921625614166\n",
      "Epoch: 399, Loss: 0.1411500722169876\n",
      "Epoch: 400, Loss: 0.09428417682647705\n",
      "Epoch: 401, Loss: 0.13276778161525726\n",
      "Epoch: 402, Loss: 0.14982321858406067\n",
      "Epoch: 403, Loss: 0.1052490696310997\n",
      "Epoch: 404, Loss: 0.14280900359153748\n",
      "Epoch: 405, Loss: 0.14187441766262054\n",
      "Epoch: 406, Loss: 0.16202028095722198\n",
      "Epoch: 407, Loss: 0.14144808053970337\n",
      "Epoch: 408, Loss: 0.1737077534198761\n",
      "Epoch: 409, Loss: 0.14117023348808289\n",
      "Epoch: 410, Loss: 0.14209231734275818\n",
      "Epoch: 411, Loss: 0.10442201793193817\n",
      "Epoch: 412, Loss: 0.1855703592300415\n",
      "Epoch: 413, Loss: 0.13988086581230164\n",
      "Epoch: 414, Loss: 0.13949617743492126\n",
      "Epoch: 415, Loss: 0.09285984933376312\n",
      "Epoch: 416, Loss: 0.14040815830230713\n",
      "Epoch: 417, Loss: 0.17258623242378235\n",
      "Epoch: 418, Loss: 0.09247912466526031\n",
      "Epoch: 419, Loss: 0.1390811800956726\n",
      "Epoch: 420, Loss: 0.15196186304092407\n",
      "Epoch: 421, Loss: 0.13202856481075287\n",
      "Epoch: 422, Loss: 0.09195413440465927\n",
      "Epoch: 423, Loss: 0.09150349348783493\n",
      "Epoch: 424, Loss: 0.13868798315525055\n",
      "Epoch: 425, Loss: 0.14817114174365997\n",
      "Epoch: 426, Loss: 0.17151287198066711\n",
      "Epoch: 427, Loss: 0.13950374722480774\n",
      "Epoch: 428, Loss: 0.15084075927734375\n",
      "Epoch: 429, Loss: 0.09091776609420776\n",
      "Epoch: 430, Loss: 0.13037298619747162\n",
      "Epoch: 431, Loss: 0.130061537027359\n",
      "Epoch: 432, Loss: 0.1473960429430008\n",
      "Epoch: 433, Loss: 0.13816331326961517\n",
      "Epoch: 434, Loss: 0.18203547596931458\n",
      "Epoch: 435, Loss: 0.13974826037883759\n",
      "Epoch: 436, Loss: 0.09028727561235428\n",
      "Epoch: 437, Loss: 0.15850436687469482\n",
      "Epoch: 438, Loss: 0.13747957348823547\n",
      "Epoch: 439, Loss: 0.1383533477783203\n",
      "Epoch: 440, Loss: 0.12549754977226257\n",
      "Epoch: 441, Loss: 0.1381155550479889\n",
      "Epoch: 442, Loss: 0.12450996041297913\n",
      "Epoch: 443, Loss: 0.08920307457447052\n",
      "Epoch: 444, Loss: 0.1577579379081726\n",
      "Epoch: 445, Loss: 0.14658035337924957\n",
      "Epoch: 446, Loss: 0.15745270252227783\n",
      "Epoch: 447, Loss: 0.14875122904777527\n",
      "Epoch: 448, Loss: 0.1484242081642151\n",
      "Epoch: 449, Loss: 0.10117089748382568\n",
      "Epoch: 450, Loss: 0.12343122065067291\n",
      "Epoch: 451, Loss: 0.13665024936199188\n",
      "Epoch: 452, Loss: 0.16877694427967072\n",
      "Epoch: 453, Loss: 0.17937764525413513\n",
      "Epoch: 454, Loss: 0.1564716249704361\n",
      "Epoch: 455, Loss: 0.12309631705284119\n",
      "Epoch: 456, Loss: 0.10035798698663712\n",
      "Epoch: 457, Loss: 0.1561296433210373\n",
      "Epoch: 458, Loss: 0.16804489493370056\n",
      "Epoch: 459, Loss: 0.14549314975738525\n",
      "Epoch: 460, Loss: 0.12786200642585754\n",
      "Epoch: 461, Loss: 0.1291644126176834\n",
      "Epoch: 462, Loss: 0.16735254228115082\n",
      "Epoch: 463, Loss: 0.1555025279521942\n",
      "Epoch: 464, Loss: 0.15520091354846954\n",
      "Epoch: 465, Loss: 0.09982378035783768\n",
      "Epoch: 466, Loss: 0.08793969452381134\n",
      "Epoch: 467, Loss: 0.12735359370708466\n",
      "Epoch: 468, Loss: 0.09937875717878342\n",
      "Epoch: 469, Loss: 0.17707671225070953\n",
      "Epoch: 470, Loss: 0.13528111577033997\n",
      "Epoch: 471, Loss: 0.1365627646446228\n",
      "Epoch: 472, Loss: 0.14580221474170685\n",
      "Epoch: 473, Loss: 0.15422241389751434\n",
      "Epoch: 474, Loss: 0.08736182749271393\n",
      "Epoch: 475, Loss: 0.08694477379322052\n",
      "Epoch: 476, Loss: 0.1283113807439804\n",
      "Epoch: 477, Loss: 0.1451878398656845\n",
      "Epoch: 478, Loss: 0.1658029407262802\n",
      "Epoch: 479, Loss: 0.08672472834587097\n",
      "Epoch: 480, Loss: 0.13450081646442413\n",
      "Epoch: 481, Loss: 0.14392313361167908\n",
      "Epoch: 482, Loss: 0.15340638160705566\n",
      "Epoch: 483, Loss: 0.09852253645658493\n",
      "Epoch: 484, Loss: 0.08624977618455887\n",
      "Epoch: 485, Loss: 0.1435527801513672\n",
      "Epoch: 486, Loss: 0.08591140061616898\n",
      "Epoch: 487, Loss: 0.13394944369792938\n",
      "Epoch: 488, Loss: 0.1527988612651825\n",
      "Epoch: 489, Loss: 0.17426851391792297\n",
      "Epoch: 490, Loss: 0.1437305510044098\n",
      "Epoch: 491, Loss: 0.12733867764472961\n",
      "Epoch: 492, Loss: 0.1347547322511673\n",
      "Epoch: 493, Loss: 0.1342857927083969\n",
      "Epoch: 494, Loss: 0.16420377790927887\n",
      "Epoch: 495, Loss: 0.1520383358001709\n",
      "Epoch: 496, Loss: 0.08537312597036362\n",
      "Epoch: 497, Loss: 0.08498573303222656\n",
      "Epoch: 498, Loss: 0.14289185404777527\n",
      "Epoch: 499, Loss: 0.1340666115283966\n",
      "Epoch: 500, Loss: 0.08467207849025726\n",
      "Epoch: 501, Loss: 0.12673763930797577\n",
      "Epoch: 502, Loss: 0.14226287603378296\n",
      "Epoch: 503, Loss: 0.13354849815368652\n",
      "Epoch: 504, Loss: 0.09718991070985794\n",
      "Epoch: 505, Loss: 0.1720171421766281\n",
      "Epoch: 506, Loss: 0.17100313305854797\n",
      "Epoch: 507, Loss: 0.12618526816368103\n",
      "Epoch: 508, Loss: 0.08441660553216934\n",
      "Epoch: 509, Loss: 0.14166703820228577\n",
      "Epoch: 510, Loss: 0.1259782910346985\n",
      "Epoch: 511, Loss: 0.12578290700912476\n",
      "Epoch: 512, Loss: 0.13291460275650024\n",
      "Epoch: 513, Loss: 0.08396643400192261\n",
      "Epoch: 514, Loss: 0.12564891576766968\n",
      "Epoch: 515, Loss: 0.13253231346607208\n",
      "Epoch: 516, Loss: 0.1327444165945053\n",
      "Epoch: 517, Loss: 0.12381727993488312\n",
      "Epoch: 518, Loss: 0.1234978586435318\n",
      "Epoch: 519, Loss: 0.12331754714250565\n",
      "Epoch: 520, Loss: 0.12310735881328583\n",
      "Epoch: 521, Loss: 0.13225026428699493\n",
      "Epoch: 522, Loss: 0.09610329568386078\n",
      "Epoch: 523, Loss: 0.11507460474967957\n",
      "Epoch: 524, Loss: 0.11457105726003647\n",
      "Epoch: 525, Loss: 0.11394567787647247\n",
      "Epoch: 526, Loss: 0.1320311725139618\n",
      "Epoch: 527, Loss: 0.14057913422584534\n",
      "Epoch: 528, Loss: 0.09528720378875732\n",
      "Epoch: 529, Loss: 0.1315183937549591\n",
      "Epoch: 530, Loss: 0.13151180744171143\n",
      "Epoch: 531, Loss: 0.14913427829742432\n",
      "Epoch: 532, Loss: 0.09496530145406723\n",
      "Epoch: 533, Loss: 0.13131551444530487\n",
      "Epoch: 534, Loss: 0.12247305363416672\n",
      "Epoch: 535, Loss: 0.11308597773313522\n",
      "Epoch: 536, Loss: 0.13924676179885864\n",
      "Epoch: 537, Loss: 0.16061469912528992\n",
      "Epoch: 538, Loss: 0.12436024844646454\n",
      "Epoch: 539, Loss: 0.13087612390518188\n",
      "Epoch: 540, Loss: 0.1307806819677353\n",
      "Epoch: 541, Loss: 0.13851749897003174\n",
      "Epoch: 542, Loss: 0.13049714267253876\n",
      "Epoch: 543, Loss: 0.1599266678094864\n",
      "Epoch: 544, Loss: 0.13065294921398163\n",
      "Epoch: 545, Loss: 0.1303989291191101\n",
      "Epoch: 546, Loss: 0.13019394874572754\n",
      "Epoch: 547, Loss: 0.12172286212444305\n",
      "Epoch: 548, Loss: 0.15940015017986298\n",
      "Epoch: 549, Loss: 0.13009780645370483\n",
      "Epoch: 550, Loss: 0.08204624801874161\n",
      "Epoch: 551, Loss: 0.12999239563941956\n",
      "Epoch: 552, Loss: 0.12973201274871826\n",
      "Epoch: 553, Loss: 0.1296873539686203\n",
      "Epoch: 554, Loss: 0.12956468760967255\n",
      "Epoch: 555, Loss: 0.15899434685707092\n",
      "Epoch: 556, Loss: 0.12937593460083008\n",
      "Epoch: 557, Loss: 0.16547872126102448\n",
      "Epoch: 558, Loss: 0.15840254724025726\n",
      "Epoch: 559, Loss: 0.0816073790192604\n",
      "Epoch: 560, Loss: 0.13673295080661774\n",
      "Epoch: 561, Loss: 0.1292029768228531\n",
      "Epoch: 562, Loss: 0.1580614447593689\n",
      "Epoch: 563, Loss: 0.12894994020462036\n",
      "Epoch: 564, Loss: 0.1362600326538086\n",
      "Epoch: 565, Loss: 0.12872564792633057\n",
      "Epoch: 566, Loss: 0.08105634152889252\n",
      "Epoch: 567, Loss: 0.12896853685379028\n",
      "Epoch: 568, Loss: 0.14613518118858337\n",
      "Epoch: 569, Loss: 0.12864504754543304\n",
      "Epoch: 570, Loss: 0.12837421894073486\n",
      "Epoch: 571, Loss: 0.09313513338565826\n",
      "Epoch: 572, Loss: 0.13552449643611908\n",
      "Epoch: 573, Loss: 0.13792511820793152\n",
      "Epoch: 574, Loss: 0.10964296758174896\n",
      "Epoch: 575, Loss: 0.09255771338939667\n",
      "Epoch: 576, Loss: 0.12248653918504715\n",
      "Epoch: 577, Loss: 0.1374742090702057\n",
      "Epoch: 578, Loss: 0.0804896280169487\n",
      "Epoch: 579, Loss: 0.1277850717306137\n",
      "Epoch: 580, Loss: 0.0801258236169815\n",
      "Epoch: 581, Loss: 0.13721871376037598\n",
      "Epoch: 582, Loss: 0.15656813979148865\n",
      "Epoch: 583, Loss: 0.1369369924068451\n",
      "Epoch: 584, Loss: 0.07990190386772156\n",
      "Epoch: 585, Loss: 0.1344875991344452\n",
      "Epoch: 586, Loss: 0.16228513419628143\n",
      "Epoch: 587, Loss: 0.15594738721847534\n",
      "Epoch: 588, Loss: 0.12714606523513794\n",
      "Epoch: 589, Loss: 0.09213630855083466\n",
      "Epoch: 590, Loss: 0.10813046246767044\n",
      "Epoch: 591, Loss: 0.14457373321056366\n",
      "Epoch: 592, Loss: 0.07945489883422852\n",
      "Epoch: 593, Loss: 0.12667228281497955\n",
      "Epoch: 594, Loss: 0.15556670725345612\n",
      "Epoch: 595, Loss: 0.13622789084911346\n",
      "Epoch: 596, Loss: 0.11865688860416412\n",
      "Epoch: 597, Loss: 0.1359582543373108\n",
      "Epoch: 598, Loss: 0.1608518660068512\n",
      "Epoch: 599, Loss: 0.12723444402217865\n",
      "Epoch: 600, Loss: 0.12714070081710815\n",
      "Epoch: 601, Loss: 0.12693239748477936\n",
      "Epoch: 602, Loss: 0.14357465505599976\n",
      "Epoch: 603, Loss: 0.1259680539369583\n",
      "Epoch: 604, Loss: 0.15974068641662598\n",
      "Epoch: 605, Loss: 0.14323870837688446\n",
      "Epoch: 606, Loss: 0.126775324344635\n",
      "Epoch: 607, Loss: 0.13552416861057281\n",
      "Epoch: 608, Loss: 0.14296892285346985\n",
      "Epoch: 609, Loss: 0.11808012425899506\n",
      "Epoch: 610, Loss: 0.10644036531448364\n",
      "Epoch: 611, Loss: 0.13506059348583221\n",
      "Epoch: 612, Loss: 0.15923459827899933\n",
      "Epoch: 613, Loss: 0.12057916820049286\n",
      "Epoch: 614, Loss: 0.10589271783828735\n",
      "Epoch: 615, Loss: 0.12648452818393707\n",
      "Epoch: 616, Loss: 0.14242441952228546\n",
      "Epoch: 617, Loss: 0.10527709126472473\n",
      "Epoch: 618, Loss: 0.07827863842248917\n",
      "Epoch: 619, Loss: 0.1203925609588623\n",
      "Epoch: 620, Loss: 0.1584562063217163\n",
      "Epoch: 621, Loss: 0.10507544875144958\n",
      "Epoch: 622, Loss: 0.1261010468006134\n",
      "Epoch: 623, Loss: 0.14187106490135193\n",
      "Epoch: 624, Loss: 0.14159654080867767\n",
      "Epoch: 625, Loss: 0.15758037567138672\n",
      "Epoch: 626, Loss: 0.09022492915391922\n",
      "Epoch: 627, Loss: 0.1342029720544815\n",
      "Epoch: 628, Loss: 0.15303389728069305\n",
      "Epoch: 629, Loss: 0.1569136083126068\n",
      "Epoch: 630, Loss: 0.11676783859729767\n",
      "Epoch: 631, Loss: 0.13384558260440826\n",
      "Epoch: 632, Loss: 0.1164868026971817\n",
      "Epoch: 633, Loss: 0.07770473510026932\n",
      "Epoch: 634, Loss: 0.15248623490333557\n",
      "Epoch: 635, Loss: 0.08974520862102509\n",
      "Epoch: 636, Loss: 0.15596218407154083\n",
      "Epoch: 637, Loss: 0.12530499696731567\n",
      "Epoch: 638, Loss: 0.12386772036552429\n",
      "Epoch: 639, Loss: 0.1333317756652832\n",
      "Epoch: 640, Loss: 0.1406089961528778\n",
      "Epoch: 641, Loss: 0.0772661343216896\n",
      "Epoch: 642, Loss: 0.13002875447273254\n",
      "Epoch: 643, Loss: 0.12980462610721588\n",
      "Epoch: 644, Loss: 0.15513232350349426\n",
      "Epoch: 645, Loss: 0.15458914637565613\n",
      "Epoch: 646, Loss: 0.10350796580314636\n",
      "Epoch: 647, Loss: 0.11897759139537811\n",
      "Epoch: 648, Loss: 0.15437260270118713\n",
      "Epoch: 649, Loss: 0.12473604083061218\n",
      "Epoch: 650, Loss: 0.12310430407524109\n",
      "Epoch: 651, Loss: 0.11876225471496582\n",
      "Epoch: 652, Loss: 0.12906767427921295\n",
      "Epoch: 653, Loss: 0.11856263875961304\n",
      "Epoch: 654, Loss: 0.10224252194166183\n",
      "Epoch: 655, Loss: 0.15094482898712158\n",
      "Epoch: 656, Loss: 0.08863990753889084\n",
      "Epoch: 657, Loss: 0.1226818859577179\n",
      "Epoch: 658, Loss: 0.11829718947410583\n",
      "Epoch: 659, Loss: 0.13220897316932678\n",
      "Epoch: 660, Loss: 0.1243085041642189\n",
      "Epoch: 661, Loss: 0.08828867226839066\n",
      "Epoch: 662, Loss: 0.1283586025238037\n",
      "Epoch: 663, Loss: 0.15325963497161865\n",
      "Epoch: 664, Loss: 0.12387724220752716\n",
      "Epoch: 665, Loss: 0.12802869081497192\n",
      "Epoch: 666, Loss: 0.1278204619884491\n",
      "Epoch: 667, Loss: 0.15252692997455597\n",
      "Epoch: 668, Loss: 0.11785653233528137\n",
      "Epoch: 669, Loss: 0.0763828456401825\n",
      "Epoch: 670, Loss: 0.13161639869213104\n",
      "Epoch: 671, Loss: 0.1218445897102356\n",
      "Epoch: 672, Loss: 0.13140027225017548\n",
      "Epoch: 673, Loss: 0.13123784959316254\n",
      "Epoch: 674, Loss: 0.14960961043834686\n",
      "Epoch: 675, Loss: 0.14936646819114685\n",
      "Epoch: 676, Loss: 0.1270965039730072\n",
      "Epoch: 677, Loss: 0.12343577295541763\n",
      "Epoch: 678, Loss: 0.08757336437702179\n",
      "Epoch: 679, Loss: 0.14908401668071747\n",
      "Epoch: 680, Loss: 0.07576848566532135\n",
      "Epoch: 681, Loss: 0.08739124238491058\n",
      "Epoch: 682, Loss: 0.11721810698509216\n",
      "Epoch: 683, Loss: 0.13788728415966034\n",
      "Epoch: 684, Loss: 0.12650664150714874\n",
      "Epoch: 685, Loss: 0.1306528002023697\n",
      "Epoch: 686, Loss: 0.09918229281902313\n",
      "Epoch: 687, Loss: 0.1230078935623169\n",
      "Epoch: 688, Loss: 0.13049884140491486\n",
      "Epoch: 689, Loss: 0.12280815094709396\n",
      "Epoch: 690, Loss: 0.11699008196592331\n",
      "Epoch: 691, Loss: 0.13729068636894226\n",
      "Epoch: 692, Loss: 0.1259341835975647\n",
      "Epoch: 693, Loss: 0.13015210628509521\n",
      "Epoch: 694, Loss: 0.08660777658224106\n",
      "Epoch: 695, Loss: 0.12252981960773468\n",
      "Epoch: 696, Loss: 0.12238112092018127\n",
      "Epoch: 697, Loss: 0.11671237647533417\n",
      "Epoch: 698, Loss: 0.12033270299434662\n",
      "Epoch: 699, Loss: 0.11324980109930038\n",
      "Epoch: 700, Loss: 0.09811025857925415\n",
      "Epoch: 701, Loss: 0.12219487875699997\n",
      "Epoch: 702, Loss: 0.08609528094530106\n",
      "Epoch: 703, Loss: 0.1476384997367859\n",
      "Epoch: 704, Loss: 0.14738783240318298\n",
      "Epoch: 705, Loss: 0.074863500893116\n",
      "Epoch: 706, Loss: 0.14959007501602173\n",
      "Epoch: 707, Loss: 0.08597106486558914\n",
      "Epoch: 708, Loss: 0.1294735074043274\n",
      "Epoch: 709, Loss: 0.11265590041875839\n",
      "Epoch: 710, Loss: 0.14909452199935913\n",
      "Epoch: 711, Loss: 0.12459398806095123\n",
      "Epoch: 712, Loss: 0.12444449216127396\n",
      "Epoch: 713, Loss: 0.12172350287437439\n",
      "Epoch: 714, Loss: 0.14669713377952576\n",
      "Epoch: 715, Loss: 0.1464734673500061\n",
      "Epoch: 716, Loss: 0.1215590238571167\n",
      "Epoch: 717, Loss: 0.12903811037540436\n",
      "Epoch: 718, Loss: 0.08541208505630493\n",
      "Epoch: 719, Loss: 0.09656814485788345\n",
      "Epoch: 720, Loss: 0.12392023205757141\n",
      "Epoch: 721, Loss: 0.1190943792462349\n",
      "Epoch: 722, Loss: 0.11206851899623871\n",
      "Epoch: 723, Loss: 0.12130720913410187\n",
      "Epoch: 724, Loss: 0.07403974235057831\n",
      "Epoch: 725, Loss: 0.11874909698963165\n",
      "Epoch: 726, Loss: 0.14591796696186066\n",
      "Epoch: 727, Loss: 0.12343443930149078\n",
      "Epoch: 728, Loss: 0.1474936604499817\n",
      "Epoch: 729, Loss: 0.11172813177108765\n",
      "Epoch: 730, Loss: 0.11520630866289139\n",
      "Epoch: 731, Loss: 0.07380317151546478\n",
      "Epoch: 732, Loss: 0.09579071402549744\n",
      "Epoch: 733, Loss: 0.1207752600312233\n",
      "Epoch: 734, Loss: 0.12056505680084229\n",
      "Epoch: 735, Loss: 0.11816655844449997\n",
      "Epoch: 736, Loss: 0.1452590376138687\n",
      "Epoch: 737, Loss: 0.14665423333644867\n",
      "Epoch: 738, Loss: 0.1463039517402649\n",
      "Epoch: 739, Loss: 0.14587166905403137\n",
      "Epoch: 740, Loss: 0.1178729385137558\n",
      "Epoch: 741, Loss: 0.1204584464430809\n",
      "Epoch: 742, Loss: 0.07324864715337753\n",
      "Epoch: 743, Loss: 0.1200346052646637\n",
      "Epoch: 744, Loss: 0.11480977386236191\n",
      "Epoch: 745, Loss: 0.12780460715293884\n",
      "Epoch: 746, Loss: 0.14543502032756805\n",
      "Epoch: 747, Loss: 0.12215477973222733\n",
      "Epoch: 748, Loss: 0.08441362529993057\n",
      "Epoch: 749, Loss: 0.1275026947259903\n",
      "Epoch: 750, Loss: 0.13372604548931122\n",
      "Epoch: 751, Loss: 0.11722984910011292\n",
      "Epoch: 752, Loss: 0.0840468481183052\n",
      "Epoch: 753, Loss: 0.11967863142490387\n",
      "Epoch: 754, Loss: 0.14410023391246796\n",
      "Epoch: 755, Loss: 0.14391332864761353\n",
      "Epoch: 756, Loss: 0.11420537531375885\n",
      "Epoch: 757, Loss: 0.14445064961910248\n",
      "Epoch: 758, Loss: 0.12711545825004578\n",
      "Epoch: 759, Loss: 0.11398392170667648\n",
      "Epoch: 760, Loss: 0.1434054970741272\n",
      "Epoch: 761, Loss: 0.12127950042486191\n",
      "Epoch: 762, Loss: 0.11937880516052246\n",
      "Epoch: 763, Loss: 0.11666157096624374\n",
      "Epoch: 764, Loss: 0.11645368486642838\n",
      "Epoch: 765, Loss: 0.11626452207565308\n",
      "Epoch: 766, Loss: 0.12095868587493896\n",
      "Epoch: 767, Loss: 0.12666191160678864\n",
      "Epoch: 768, Loss: 0.10994814336299896\n",
      "Epoch: 769, Loss: 0.12072557955980301\n",
      "Epoch: 770, Loss: 0.14285528659820557\n",
      "Epoch: 771, Loss: 0.08322267979383469\n",
      "Epoch: 772, Loss: 0.09288161993026733\n",
      "Epoch: 773, Loss: 0.11349771916866302\n",
      "Epoch: 774, Loss: 0.11593418568372726\n",
      "Epoch: 775, Loss: 0.14327701926231384\n",
      "Epoch: 776, Loss: 0.14283387362957\n",
      "Epoch: 777, Loss: 0.11909136176109314\n",
      "Epoch: 778, Loss: 0.07218191027641296\n",
      "Epoch: 779, Loss: 0.14240750670433044\n",
      "Epoch: 780, Loss: 0.07206566631793976\n",
      "Epoch: 781, Loss: 0.11321492493152618\n",
      "Epoch: 782, Loss: 0.10928232222795486\n",
      "Epoch: 783, Loss: 0.07181894779205322\n",
      "Epoch: 784, Loss: 0.10908947885036469\n",
      "Epoch: 785, Loss: 0.1419045776128769\n",
      "Epoch: 786, Loss: 0.09194646775722504\n",
      "Epoch: 787, Loss: 0.14176960289478302\n",
      "Epoch: 788, Loss: 0.11964534968137741\n",
      "Epoch: 789, Loss: 0.0826384648680687\n",
      "Epoch: 790, Loss: 0.1314970850944519\n",
      "Epoch: 791, Loss: 0.14162594079971313\n",
      "Epoch: 792, Loss: 0.1312151849269867\n",
      "Epoch: 793, Loss: 0.07152292132377625\n",
      "Epoch: 794, Loss: 0.1413431316614151\n",
      "Epoch: 795, Loss: 0.1254267543554306\n",
      "Epoch: 796, Loss: 0.11810865998268127\n",
      "Epoch: 797, Loss: 0.11908628046512604\n",
      "Epoch: 798, Loss: 0.14099785685539246\n",
      "Epoch: 799, Loss: 0.1252206563949585\n",
      "Epoch: 800, Loss: 0.11245681345462799\n",
      "Epoch: 801, Loss: 0.09093576669692993\n",
      "Epoch: 802, Loss: 0.11463333666324615\n",
      "Epoch: 803, Loss: 0.1082959994673729\n",
      "Epoch: 804, Loss: 0.11225797235965729\n",
      "Epoch: 805, Loss: 0.12480545789003372\n",
      "Epoch: 806, Loss: 0.11801941692829132\n",
      "Epoch: 807, Loss: 0.12471858412027359\n",
      "Epoch: 808, Loss: 0.11208464205265045\n",
      "Epoch: 809, Loss: 0.14045731723308563\n",
      "Epoch: 810, Loss: 0.11835626512765884\n",
      "Epoch: 811, Loss: 0.12439827620983124\n",
      "Epoch: 812, Loss: 0.11818511039018631\n",
      "Epoch: 813, Loss: 0.11803383380174637\n",
      "Epoch: 814, Loss: 0.11749865859746933\n",
      "Epoch: 815, Loss: 0.08975230902433395\n",
      "Epoch: 816, Loss: 0.11390270292758942\n",
      "Epoch: 817, Loss: 0.11724182963371277\n",
      "Epoch: 818, Loss: 0.11364098638296127\n",
      "Epoch: 819, Loss: 0.13980214297771454\n",
      "Epoch: 820, Loss: 0.07064931839704514\n",
      "Epoch: 821, Loss: 0.08936390280723572\n",
      "Epoch: 822, Loss: 0.11343339830636978\n",
      "Epoch: 823, Loss: 0.1295848935842514\n",
      "Epoch: 824, Loss: 0.08875681459903717\n",
      "Epoch: 825, Loss: 0.11705575883388519\n",
      "Epoch: 826, Loss: 0.11678466200828552\n",
      "Epoch: 827, Loss: 0.11163203418254852\n",
      "Epoch: 828, Loss: 0.08828938752412796\n",
      "Epoch: 829, Loss: 0.11727316677570343\n",
      "Epoch: 830, Loss: 0.12913787364959717\n",
      "Epoch: 831, Loss: 0.12895746529102325\n",
      "Epoch: 832, Loss: 0.08804064989089966\n",
      "Epoch: 833, Loss: 0.11296075582504272\n",
      "Epoch: 834, Loss: 0.11129209399223328\n",
      "Epoch: 835, Loss: 0.11691577732563019\n",
      "Epoch: 836, Loss: 0.1110486388206482\n",
      "Epoch: 837, Loss: 0.13856256008148193\n",
      "Epoch: 838, Loss: 0.1234932541847229\n",
      "Epoch: 839, Loss: 0.1163930743932724\n",
      "Epoch: 840, Loss: 0.1069350466132164\n",
      "Epoch: 841, Loss: 0.08750870823860168\n",
      "Epoch: 842, Loss: 0.08712596446275711\n",
      "Epoch: 843, Loss: 0.11619880795478821\n",
      "Epoch: 844, Loss: 0.13872002065181732\n",
      "Epoch: 845, Loss: 0.11596959829330444\n",
      "Epoch: 846, Loss: 0.10663175582885742\n",
      "Epoch: 847, Loss: 0.11635302007198334\n",
      "Epoch: 848, Loss: 0.110724076628685\n",
      "Epoch: 849, Loss: 0.08672308921813965\n",
      "Epoch: 850, Loss: 0.06981659680604935\n",
      "Epoch: 851, Loss: 0.06949570775032043\n",
      "Epoch: 852, Loss: 0.12792745232582092\n",
      "Epoch: 853, Loss: 0.11048358678817749\n",
      "Epoch: 854, Loss: 0.11602598428726196\n",
      "Epoch: 855, Loss: 0.13806657493114471\n",
      "Epoch: 856, Loss: 0.11578162759542465\n",
      "Epoch: 857, Loss: 0.11563490331172943\n",
      "Epoch: 858, Loss: 0.11020022630691528\n",
      "Epoch: 859, Loss: 0.1376313865184784\n",
      "Epoch: 860, Loss: 0.06936874240636826\n",
      "Epoch: 861, Loss: 0.13745316863059998\n",
      "Epoch: 862, Loss: 0.13666397333145142\n",
      "Epoch: 863, Loss: 0.11567322909832001\n",
      "Epoch: 864, Loss: 0.13723044097423553\n",
      "Epoch: 865, Loss: 0.10997414588928223\n",
      "Epoch: 866, Loss: 0.12723980844020844\n",
      "Epoch: 867, Loss: 0.06907934695482254\n",
      "Epoch: 868, Loss: 0.11504718661308289\n",
      "Epoch: 869, Loss: 0.07982349395751953\n",
      "Epoch: 870, Loss: 0.13595303893089294\n",
      "Epoch: 871, Loss: 0.07959522306919098\n",
      "Epoch: 872, Loss: 0.1222434937953949\n",
      "Epoch: 873, Loss: 0.11527828872203827\n",
      "Epoch: 874, Loss: 0.126745343208313\n",
      "Epoch: 875, Loss: 0.12658144533634186\n",
      "Epoch: 876, Loss: 0.13542252779006958\n",
      "Epoch: 877, Loss: 0.11493375897407532\n",
      "Epoch: 878, Loss: 0.11098979413509369\n",
      "Epoch: 879, Loss: 0.0792040079832077\n",
      "Epoch: 880, Loss: 0.13649430871009827\n",
      "Epoch: 881, Loss: 0.13627195358276367\n",
      "Epoch: 882, Loss: 0.11494970321655273\n",
      "Epoch: 883, Loss: 0.12182015180587769\n",
      "Epoch: 884, Loss: 0.12611502408981323\n",
      "Epoch: 885, Loss: 0.11462127417325974\n",
      "Epoch: 886, Loss: 0.10514603555202484\n",
      "Epoch: 887, Loss: 0.1259169578552246\n",
      "Epoch: 888, Loss: 0.10494313389062881\n",
      "Epoch: 889, Loss: 0.11459527909755707\n",
      "Epoch: 890, Loss: 0.1345404088497162\n",
      "Epoch: 891, Loss: 0.11386089026927948\n",
      "Epoch: 892, Loss: 0.08463723212480545\n",
      "Epoch: 893, Loss: 0.11432984471321106\n",
      "Epoch: 894, Loss: 0.1092127338051796\n",
      "Epoch: 895, Loss: 0.1341809630393982\n",
      "Epoch: 896, Loss: 0.1212758719921112\n",
      "Epoch: 897, Loss: 0.10897470265626907\n",
      "Epoch: 898, Loss: 0.13537895679473877\n",
      "Epoch: 899, Loss: 0.1253613829612732\n",
      "Epoch: 900, Loss: 0.07836705446243286\n",
      "Epoch: 901, Loss: 0.1133623868227005\n",
      "Epoch: 902, Loss: 0.07808516174554825\n",
      "Epoch: 903, Loss: 0.07785831391811371\n",
      "Epoch: 904, Loss: 0.07763626426458359\n",
      "Epoch: 905, Loss: 0.1249663308262825\n",
      "Epoch: 906, Loss: 0.11392693221569061\n",
      "Epoch: 907, Loss: 0.10973666608333588\n",
      "Epoch: 908, Loss: 0.10425703227519989\n",
      "Epoch: 909, Loss: 0.1095736101269722\n",
      "Epoch: 910, Loss: 0.13315775990486145\n",
      "Epoch: 911, Loss: 0.1093992218375206\n",
      "Epoch: 912, Loss: 0.08336794376373291\n",
      "Epoch: 913, Loss: 0.10396752506494522\n",
      "Epoch: 914, Loss: 0.10921798646450043\n",
      "Epoch: 915, Loss: 0.12444872409105301\n",
      "Epoch: 916, Loss: 0.10901017487049103\n",
      "Epoch: 917, Loss: 0.13267579674720764\n",
      "Epoch: 918, Loss: 0.11350475251674652\n",
      "Epoch: 919, Loss: 0.108817920088768\n",
      "Epoch: 920, Loss: 0.12042954564094543\n",
      "Epoch: 921, Loss: 0.10833130776882172\n",
      "Epoch: 922, Loss: 0.10815659165382385\n",
      "Epoch: 923, Loss: 0.10350792855024338\n",
      "Epoch: 924, Loss: 0.08257205039262772\n",
      "Epoch: 925, Loss: 0.11327581107616425\n",
      "Epoch: 926, Loss: 0.1130639910697937\n",
      "Epoch: 927, Loss: 0.10807348042726517\n",
      "Epoch: 928, Loss: 0.13397757709026337\n",
      "Epoch: 929, Loss: 0.1318376213312149\n",
      "Epoch: 930, Loss: 0.11998756229877472\n",
      "Epoch: 931, Loss: 0.13367316126823425\n",
      "Epoch: 932, Loss: 0.11189509928226471\n",
      "Epoch: 933, Loss: 0.11177988350391388\n",
      "Epoch: 934, Loss: 0.10773676633834839\n",
      "Epoch: 935, Loss: 0.11970265209674835\n",
      "Epoch: 936, Loss: 0.10828088223934174\n",
      "Epoch: 937, Loss: 0.11156979203224182\n",
      "Epoch: 938, Loss: 0.11292006820440292\n",
      "Epoch: 939, Loss: 0.1127452552318573\n",
      "Epoch: 940, Loss: 0.10794349759817123\n",
      "Epoch: 941, Loss: 0.06756278872489929\n",
      "Epoch: 942, Loss: 0.11944086104631424\n",
      "Epoch: 943, Loss: 0.07645411044359207\n",
      "Epoch: 944, Loss: 0.13308410346508026\n",
      "Epoch: 945, Loss: 0.06750153005123138\n",
      "Epoch: 946, Loss: 0.0763835534453392\n",
      "Epoch: 947, Loss: 0.1110980361700058\n",
      "Epoch: 948, Loss: 0.13282430171966553\n",
      "Epoch: 949, Loss: 0.0810985267162323\n",
      "Epoch: 950, Loss: 0.1326306164264679\n",
      "Epoch: 951, Loss: 0.06733746826648712\n",
      "Epoch: 952, Loss: 0.10252580046653748\n",
      "Epoch: 953, Loss: 0.0671134889125824\n",
      "Epoch: 954, Loss: 0.08076468110084534\n",
      "Epoch: 955, Loss: 0.13047127425670624\n",
      "Epoch: 956, Loss: 0.10737094283103943\n",
      "Epoch: 957, Loss: 0.06690913438796997\n",
      "Epoch: 958, Loss: 0.13002562522888184\n",
      "Epoch: 959, Loss: 0.07600883394479752\n",
      "Epoch: 960, Loss: 0.11207936704158783\n",
      "Epoch: 961, Loss: 0.1321278065443039\n",
      "Epoch: 962, Loss: 0.11210429668426514\n",
      "Epoch: 963, Loss: 0.11184033006429672\n",
      "Epoch: 964, Loss: 0.11180073767900467\n",
      "Epoch: 965, Loss: 0.10702671110630035\n",
      "Epoch: 966, Loss: 0.10211730003356934\n",
      "Epoch: 967, Loss: 0.12939031422138214\n",
      "Epoch: 968, Loss: 0.12907367944717407\n",
      "Epoch: 969, Loss: 0.11176255345344543\n",
      "Epoch: 970, Loss: 0.10195240378379822\n",
      "Epoch: 971, Loss: 0.11840853095054626\n",
      "Epoch: 972, Loss: 0.1067238599061966\n",
      "Epoch: 973, Loss: 0.10654576122760773\n",
      "Epoch: 974, Loss: 0.0799102857708931\n",
      "Epoch: 975, Loss: 0.10165627300739288\n",
      "Epoch: 976, Loss: 0.1115138828754425\n",
      "Epoch: 977, Loss: 0.10661423206329346\n",
      "Epoch: 978, Loss: 0.10640270262956619\n",
      "Epoch: 979, Loss: 0.1284714639186859\n",
      "Epoch: 980, Loss: 0.10627491027116776\n",
      "Epoch: 981, Loss: 0.10612478852272034\n",
      "Epoch: 982, Loss: 0.10598114877939224\n",
      "Epoch: 983, Loss: 0.1063268855214119\n",
      "Epoch: 984, Loss: 0.12142939865589142\n",
      "Epoch: 985, Loss: 0.10585474967956543\n",
      "Epoch: 986, Loss: 0.06622862815856934\n",
      "Epoch: 987, Loss: 0.07492554187774658\n",
      "Epoch: 988, Loss: 0.11112464964389801\n",
      "Epoch: 989, Loss: 0.11780261993408203\n",
      "Epoch: 990, Loss: 0.10562163591384888\n",
      "Epoch: 991, Loss: 0.10546645522117615\n",
      "Epoch: 992, Loss: 0.11761743575334549\n",
      "Epoch: 993, Loss: 0.1091204583644867\n",
      "Epoch: 994, Loss: 0.13057756423950195\n",
      "Epoch: 995, Loss: 0.10897025465965271\n",
      "Epoch: 996, Loss: 0.066118523478508\n",
      "Epoch: 997, Loss: 0.12075796723365784\n",
      "Epoch: 998, Loss: 0.1059064120054245\n",
      "Epoch: 999, Loss: 0.10524877905845642\n",
      "Epoch: 1000, Loss: 0.12056517601013184\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "num_epochs = 1000\n",
    "model = model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, targets) in enumerate(train_dataloader):\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {losses.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
