{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download labeling from GitHub - https://github.com/tzutalin/labelImg\n",
    "\n",
    "\n",
    "`!pip install pyqt5`\n",
    "\n",
    "`!pip install lxml`\n",
    "\n",
    "\n",
    "Installation guide - https://github.com/heartexlabs/labelImg#installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command in the terminal\n",
    "\n",
    "`pyrcc5 -o libs/resources.py resources.qrc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection.retinanet import RetinaNet_ResNet50_FPN_Weights\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Number of classes including background\n",
    "num_classes = 91 \n",
    "\n",
    "# Load a pre-trained model\n",
    "model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True, num_classes=num_classes)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Continue with your code...(Origional numbers)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "\n",
    "class YOLODataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform if transform else transforms.ToTensor()\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root_dir, \"images\"))))\n",
    "        self.labels = list(sorted(os.listdir(os.path.join(root_dir, \"labels\"))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, \"images\", self.imgs[idx])\n",
    "        label_path = os.path.join(self.root_dir, \"labels\", self.labels[idx])\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_width, img_height = img.size\n",
    "\n",
    "        # Apply transformation after getting original size\n",
    "        img = self.transform(img)\n",
    "\n",
    "        # Read YOLO label file\n",
    "        with open(label_path, \"r\") as file:\n",
    "            lines = file.read().splitlines()\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for line in lines:\n",
    "            class_id, x_center, y_center, width, height = map(float, line.split())\n",
    "            labels.append(int(class_id))\n",
    "\n",
    "            x_min = img_width * (x_center - width / 2)\n",
    "            y_min = img_height * (y_center - height / 2)\n",
    "            x_max = img_width * (x_center + width / 2)\n",
    "            y_max = img_height * (y_center + height / 2)\n",
    "            boxes.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = torch.tensor(boxes, dtype=torch.float32)\n",
    "        target['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "# Define your own paths here\n",
    "train_dataset = YOLODataset(\"data/train set\")\n",
    "valid_dataset = YOLODataset(\"data/validation set\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "\n",
    "    return images, targets\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.3914183974266052\n",
      "Epoch: 2, Loss: 0.22261570394039154\n",
      "Epoch: 3, Loss: 0.19438746571540833\n",
      "Epoch: 4, Loss: 0.15150466561317444\n",
      "Epoch: 5, Loss: 0.15073466300964355\n",
      "Epoch: 6, Loss: 0.16213205456733704\n",
      "Epoch: 7, Loss: 0.24466808140277863\n",
      "Epoch: 8, Loss: 0.17963020503520966\n",
      "Epoch: 9, Loss: 0.09760978072881699\n",
      "Epoch: 10, Loss: 0.1212872788310051\n",
      "Epoch: 11, Loss: 0.1433679610490799\n",
      "Epoch: 12, Loss: 0.07134049385786057\n",
      "Epoch: 13, Loss: 0.13470357656478882\n",
      "Epoch: 14, Loss: 0.10969513654708862\n",
      "Epoch: 15, Loss: 0.11819998919963837\n",
      "Epoch: 16, Loss: 0.11196228861808777\n",
      "Epoch: 17, Loss: 0.10838361829519272\n",
      "Epoch: 18, Loss: 0.10340055823326111\n",
      "Epoch: 19, Loss: 0.09991008788347244\n",
      "Epoch: 20, Loss: 0.08275127410888672\n",
      "Epoch: 21, Loss: 0.0967976450920105\n",
      "Epoch: 22, Loss: 0.09454929083585739\n",
      "Epoch: 23, Loss: 0.0787825733423233\n",
      "Epoch: 24, Loss: 0.09959239512681961\n",
      "Epoch: 25, Loss: 0.08469707518815994\n",
      "Epoch: 26, Loss: 0.09611109644174576\n",
      "Epoch: 27, Loss: 0.07176747918128967\n",
      "Epoch: 28, Loss: 0.07305803149938583\n",
      "Epoch: 29, Loss: 0.0658976212143898\n",
      "Epoch: 30, Loss: 0.08155819028615952\n",
      "Epoch: 31, Loss: 0.07970289885997772\n",
      "Epoch: 32, Loss: 0.08325614780187607\n",
      "Epoch: 33, Loss: 0.08996912091970444\n",
      "Epoch: 34, Loss: 0.08619149029254913\n",
      "Epoch: 35, Loss: 0.0768645852804184\n",
      "Epoch: 36, Loss: 0.08074214309453964\n",
      "Epoch: 37, Loss: 0.05396635830402374\n",
      "Epoch: 38, Loss: 0.08222045749425888\n",
      "Epoch: 39, Loss: 0.05886531621217728\n",
      "Epoch: 40, Loss: 0.06891434639692307\n",
      "Epoch: 41, Loss: 0.0715842992067337\n",
      "Epoch: 42, Loss: 0.08550804108381271\n",
      "Epoch: 43, Loss: 0.06653745472431183\n",
      "Epoch: 44, Loss: 0.07732547074556351\n",
      "Epoch: 45, Loss: 0.06272556632757187\n",
      "Epoch: 46, Loss: 0.07207946479320526\n",
      "Epoch: 47, Loss: 0.07407276332378387\n",
      "Epoch: 48, Loss: 0.06256228685379028\n",
      "Epoch: 49, Loss: 0.06663446128368378\n",
      "Epoch: 50, Loss: 0.06522560864686966\n",
      "Epoch: 51, Loss: 0.03076041489839554\n",
      "Epoch: 52, Loss: 0.05517934262752533\n",
      "Epoch: 53, Loss: 0.06829521059989929\n",
      "Epoch: 54, Loss: 0.060987260192632675\n",
      "Epoch: 55, Loss: 0.058036964386701584\n",
      "Epoch: 56, Loss: 0.02325594052672386\n",
      "Epoch: 57, Loss: 0.060538288205862045\n",
      "Epoch: 58, Loss: 0.06987060606479645\n",
      "Epoch: 59, Loss: 0.06511033326387405\n",
      "Epoch: 60, Loss: 0.06810740381479263\n",
      "Epoch: 61, Loss: 0.06628924608230591\n",
      "Epoch: 62, Loss: 0.04371675103902817\n",
      "Epoch: 63, Loss: 0.059546247124671936\n",
      "Epoch: 64, Loss: 0.040568288415670395\n",
      "Epoch: 65, Loss: 0.058853305876255035\n",
      "Epoch: 66, Loss: 0.043532323092222214\n",
      "Epoch: 67, Loss: 0.06302155554294586\n",
      "Epoch: 68, Loss: 0.05793413147330284\n",
      "Epoch: 69, Loss: 0.04079241305589676\n",
      "Epoch: 70, Loss: 0.06588587164878845\n",
      "Epoch: 71, Loss: 0.05459241569042206\n",
      "Epoch: 72, Loss: 0.046113740652799606\n",
      "Epoch: 73, Loss: 0.04730049893260002\n",
      "Epoch: 74, Loss: 0.060485243797302246\n",
      "Epoch: 75, Loss: 0.061483629047870636\n",
      "Epoch: 76, Loss: 0.027545230463147163\n",
      "Epoch: 77, Loss: 0.05575847253203392\n",
      "Epoch: 78, Loss: 0.05376579239964485\n",
      "Epoch: 79, Loss: 0.055724017322063446\n",
      "Epoch: 80, Loss: 0.0576334223151207\n",
      "Epoch: 81, Loss: 0.04976148158311844\n",
      "Epoch: 82, Loss: 0.04027450829744339\n",
      "Epoch: 83, Loss: 0.03306592255830765\n",
      "Epoch: 84, Loss: 0.05028757452964783\n",
      "Epoch: 85, Loss: 0.042642638087272644\n",
      "Epoch: 86, Loss: 0.05052342638373375\n",
      "Epoch: 87, Loss: 0.04313003271818161\n",
      "Epoch: 88, Loss: 0.04738745838403702\n",
      "Epoch: 89, Loss: 0.032916922122240067\n",
      "Epoch: 90, Loss: 0.07009211927652359\n",
      "Epoch: 91, Loss: 0.05289756879210472\n",
      "Epoch: 92, Loss: 0.0481637679040432\n",
      "Epoch: 93, Loss: 0.04358602315187454\n",
      "Epoch: 94, Loss: 0.04702780768275261\n",
      "Epoch: 95, Loss: 0.03765692561864853\n",
      "Epoch: 96, Loss: 0.03437226638197899\n",
      "Epoch: 97, Loss: 0.03399541229009628\n",
      "Epoch: 98, Loss: 0.05492782220244408\n",
      "Epoch: 99, Loss: 0.04313330352306366\n",
      "Epoch: 100, Loss: 0.027494506910443306\n",
      "Epoch: 101, Loss: 0.04764605313539505\n",
      "Epoch: 102, Loss: 0.026068059727549553\n",
      "Epoch: 103, Loss: 0.042053624987602234\n",
      "Epoch: 104, Loss: 0.03556326776742935\n",
      "Epoch: 105, Loss: 0.034728191792964935\n",
      "Epoch: 106, Loss: 0.04517088457942009\n",
      "Epoch: 107, Loss: 0.03408152237534523\n",
      "Epoch: 108, Loss: 0.034495726227760315\n",
      "Epoch: 109, Loss: 0.053443003445863724\n",
      "Epoch: 110, Loss: 0.04246378317475319\n",
      "Epoch: 111, Loss: 0.04191580042243004\n",
      "Epoch: 112, Loss: 0.03311769664287567\n",
      "Epoch: 113, Loss: 0.04993700608611107\n",
      "Epoch: 114, Loss: 0.056660499423742294\n",
      "Epoch: 115, Loss: 0.061468277126550674\n",
      "Epoch: 116, Loss: 0.05136597901582718\n",
      "Epoch: 117, Loss: 0.028550345450639725\n",
      "Epoch: 118, Loss: 0.03847689926624298\n",
      "Epoch: 119, Loss: 0.022708691656589508\n",
      "Epoch: 120, Loss: 0.04196023568511009\n",
      "Epoch: 121, Loss: 0.035092566162347794\n",
      "Epoch: 122, Loss: 0.04928315803408623\n",
      "Epoch: 123, Loss: 0.05451732501387596\n",
      "Epoch: 124, Loss: 0.0403745174407959\n",
      "Epoch: 125, Loss: 0.05021621659398079\n",
      "Epoch: 126, Loss: 0.03062909096479416\n",
      "Epoch: 127, Loss: 0.03193502873182297\n",
      "Epoch: 128, Loss: 0.0436381995677948\n",
      "Epoch: 129, Loss: 0.033384811133146286\n",
      "Epoch: 130, Loss: 0.0399591289460659\n",
      "Epoch: 131, Loss: 0.0410505011677742\n",
      "Epoch: 132, Loss: 0.046833641827106476\n",
      "Epoch: 133, Loss: 0.04280376806855202\n",
      "Epoch: 134, Loss: 0.047041766345500946\n",
      "Epoch: 135, Loss: 0.027310680598020554\n",
      "Epoch: 136, Loss: 0.03465395048260689\n",
      "Epoch: 137, Loss: 0.030497834086418152\n",
      "Epoch: 138, Loss: 0.03788655251264572\n",
      "Epoch: 139, Loss: 0.018161693587899208\n",
      "Epoch: 140, Loss: 0.04072543606162071\n",
      "Epoch: 141, Loss: 0.030986422672867775\n",
      "Epoch: 142, Loss: 0.028399942442774773\n",
      "Epoch: 143, Loss: 0.04565266892313957\n",
      "Epoch: 144, Loss: 0.030449895188212395\n",
      "Epoch: 145, Loss: 0.042678963392972946\n",
      "Epoch: 146, Loss: 0.046671729534864426\n",
      "Epoch: 147, Loss: 0.037122730165719986\n",
      "Epoch: 148, Loss: 0.04673635959625244\n",
      "Epoch: 149, Loss: 0.05088832601904869\n",
      "Epoch: 150, Loss: 0.045348670333623886\n",
      "Epoch: 151, Loss: 0.039092838764190674\n",
      "Epoch: 152, Loss: 0.06024925038218498\n",
      "Epoch: 153, Loss: 0.032534606754779816\n",
      "Epoch: 154, Loss: 0.042645812034606934\n",
      "Epoch: 155, Loss: 0.0352739579975605\n",
      "Epoch: 156, Loss: 0.032891497015953064\n",
      "Epoch: 157, Loss: 0.04324426129460335\n",
      "Epoch: 158, Loss: 0.04409260302782059\n",
      "Epoch: 159, Loss: 0.04410867765545845\n",
      "Epoch: 160, Loss: 0.04121217504143715\n",
      "Epoch: 161, Loss: 0.045447513461112976\n",
      "Epoch: 162, Loss: 0.06016664579510689\n",
      "Epoch: 163, Loss: 0.046715110540390015\n",
      "Epoch: 164, Loss: 0.052719857543706894\n",
      "Epoch: 165, Loss: 0.030397577211260796\n",
      "Epoch: 166, Loss: 0.03841308876872063\n",
      "Epoch: 167, Loss: 0.028795257210731506\n",
      "Epoch: 168, Loss: 0.012054838240146637\n",
      "Epoch: 169, Loss: 0.03271043300628662\n",
      "Epoch: 170, Loss: 0.011640522629022598\n",
      "Epoch: 171, Loss: 0.025710338726639748\n",
      "Epoch: 172, Loss: 0.03082333132624626\n",
      "Epoch: 173, Loss: 0.01829417422413826\n",
      "Epoch: 174, Loss: 0.0255767609924078\n",
      "Epoch: 175, Loss: 0.03488524630665779\n",
      "Epoch: 176, Loss: 0.025778591632843018\n",
      "Epoch: 177, Loss: 0.029848000034689903\n",
      "Epoch: 178, Loss: 0.03755483031272888\n",
      "Epoch: 179, Loss: 0.03250574320554733\n",
      "Epoch: 180, Loss: 0.020120447501540184\n",
      "Epoch: 181, Loss: 0.02646782621741295\n",
      "Epoch: 182, Loss: 0.027938904240727425\n",
      "Epoch: 183, Loss: 0.02723320946097374\n",
      "Epoch: 184, Loss: 0.02890591137111187\n",
      "Epoch: 185, Loss: 0.02578030712902546\n",
      "Epoch: 186, Loss: 0.027699889615178108\n",
      "Epoch: 187, Loss: 0.03131288290023804\n",
      "Epoch: 188, Loss: 0.03352785110473633\n",
      "Epoch: 189, Loss: 0.029346557334065437\n",
      "Epoch: 190, Loss: 0.035659123212099075\n",
      "Epoch: 191, Loss: 0.032779332250356674\n",
      "Epoch: 192, Loss: 0.02027587965130806\n",
      "Epoch: 193, Loss: 0.030278846621513367\n",
      "Epoch: 194, Loss: 0.03935566917061806\n",
      "Epoch: 195, Loss: 0.04393337666988373\n",
      "Epoch: 196, Loss: 0.045210108160972595\n",
      "Epoch: 197, Loss: 0.02418474853038788\n",
      "Epoch: 198, Loss: 0.024315377697348595\n",
      "Epoch: 199, Loss: 0.029839131981134415\n",
      "Epoch: 200, Loss: 0.03354320675134659\n",
      "Epoch: 201, Loss: 0.03244771063327789\n",
      "Epoch: 202, Loss: 0.03433813527226448\n",
      "Epoch: 203, Loss: 0.034507207572460175\n",
      "Epoch: 204, Loss: 0.02371670864522457\n",
      "Epoch: 205, Loss: 0.03096059523522854\n",
      "Epoch: 206, Loss: 0.021977156400680542\n",
      "Epoch: 207, Loss: 0.03712771087884903\n",
      "Epoch: 208, Loss: 0.02912520244717598\n",
      "Epoch: 209, Loss: 0.038917891681194305\n",
      "Epoch: 210, Loss: 0.027411991730332375\n",
      "Epoch: 211, Loss: 0.030247455462813377\n",
      "Epoch: 212, Loss: 0.029642999172210693\n",
      "Epoch: 213, Loss: 0.023557480424642563\n",
      "Epoch: 214, Loss: 0.023434991016983986\n",
      "Epoch: 215, Loss: 0.015867993235588074\n",
      "Epoch: 216, Loss: 0.01658901944756508\n",
      "Epoch: 217, Loss: 0.023778636008501053\n",
      "Epoch: 218, Loss: 0.018645955249667168\n",
      "Epoch: 219, Loss: 0.025609266012907028\n",
      "Epoch: 220, Loss: 0.025867970660328865\n",
      "Epoch: 221, Loss: 0.02361152321100235\n",
      "Epoch: 222, Loss: 0.03075677901506424\n",
      "Epoch: 223, Loss: 0.03462955728173256\n",
      "Epoch: 224, Loss: 0.01663859188556671\n",
      "Epoch: 225, Loss: 0.0221104696393013\n",
      "Epoch: 226, Loss: 0.014643659815192223\n",
      "Epoch: 227, Loss: 0.02419234812259674\n",
      "Epoch: 228, Loss: 0.0227887611836195\n",
      "Epoch: 229, Loss: 0.019062982872128487\n",
      "Epoch: 230, Loss: 0.022960422560572624\n",
      "Epoch: 231, Loss: 0.02846457064151764\n",
      "Epoch: 232, Loss: 0.0176752470433712\n",
      "Epoch: 233, Loss: 0.03626326471567154\n",
      "Epoch: 234, Loss: 0.04798107221722603\n",
      "Epoch: 235, Loss: 0.0370667427778244\n",
      "Epoch: 236, Loss: 0.02748950757086277\n",
      "Epoch: 237, Loss: 0.027087200433015823\n",
      "Epoch: 238, Loss: 0.024703027680516243\n",
      "Epoch: 239, Loss: 0.026628859341144562\n",
      "Epoch: 240, Loss: 0.0245685912668705\n",
      "Epoch: 241, Loss: 0.025164786726236343\n",
      "Epoch: 242, Loss: 0.022843606770038605\n",
      "Epoch: 243, Loss: 0.030161695554852486\n",
      "Epoch: 244, Loss: 0.022893305867910385\n",
      "Epoch: 245, Loss: 0.022937122732400894\n",
      "Epoch: 246, Loss: 0.01497988123446703\n",
      "Epoch: 247, Loss: 0.022048385813832283\n",
      "Epoch: 248, Loss: 0.019847629591822624\n",
      "Epoch: 249, Loss: 0.020952444523572922\n",
      "Epoch: 250, Loss: 0.020336860790848732\n",
      "Epoch: 251, Loss: 0.013009818270802498\n",
      "Epoch: 252, Loss: 0.03332124650478363\n",
      "Epoch: 253, Loss: 0.04624253138899803\n",
      "Epoch: 254, Loss: 0.037135180085897446\n",
      "Epoch: 255, Loss: 0.03472333773970604\n",
      "Epoch: 256, Loss: 0.02535703405737877\n",
      "Epoch: 257, Loss: 0.02336805686354637\n",
      "Epoch: 258, Loss: 0.026092711836099625\n",
      "Epoch: 259, Loss: 0.029362598434090614\n",
      "Epoch: 260, Loss: 0.03166003152728081\n",
      "Epoch: 261, Loss: 0.02516821399331093\n",
      "Epoch: 262, Loss: 0.029064670205116272\n",
      "Epoch: 263, Loss: 0.026336723938584328\n",
      "Epoch: 264, Loss: 0.019155193120241165\n",
      "Epoch: 265, Loss: 0.027335233986377716\n",
      "Epoch: 266, Loss: 0.021585596725344658\n",
      "Epoch: 267, Loss: 0.032819345593452454\n",
      "Epoch: 268, Loss: 0.03163360059261322\n",
      "Epoch: 269, Loss: 0.03157932683825493\n",
      "Epoch: 270, Loss: 0.031520191580057144\n",
      "Epoch: 271, Loss: 0.020680053159594536\n",
      "Epoch: 272, Loss: 0.031620290130376816\n",
      "Epoch: 273, Loss: 0.03120674379169941\n",
      "Epoch: 274, Loss: 0.02967127412557602\n",
      "Epoch: 275, Loss: 0.018157152459025383\n",
      "Epoch: 276, Loss: 0.015291855670511723\n",
      "Epoch: 277, Loss: 0.02816375531256199\n",
      "Epoch: 278, Loss: 0.023010166361927986\n",
      "Epoch: 279, Loss: 0.02103605307638645\n",
      "Epoch: 280, Loss: 0.02121145650744438\n",
      "Epoch: 281, Loss: 0.021631842479109764\n",
      "Epoch: 282, Loss: 0.02974073961377144\n",
      "Epoch: 283, Loss: 0.020560184493660927\n",
      "Epoch: 284, Loss: 0.03678711876273155\n",
      "Epoch: 285, Loss: 0.018500812351703644\n",
      "Epoch: 286, Loss: 0.04847192019224167\n",
      "Epoch: 287, Loss: 0.026752185076475143\n",
      "Epoch: 288, Loss: 0.033227209001779556\n",
      "Epoch: 289, Loss: 0.03362107649445534\n",
      "Epoch: 290, Loss: 0.03150901570916176\n",
      "Epoch: 291, Loss: 0.0238034687936306\n",
      "Epoch: 292, Loss: 0.02492537349462509\n",
      "Epoch: 293, Loss: 0.028053157031536102\n",
      "Epoch: 294, Loss: 0.020544297993183136\n",
      "Epoch: 295, Loss: 0.024885859340429306\n",
      "Epoch: 296, Loss: 0.0192837193608284\n",
      "Epoch: 297, Loss: 0.02430029958486557\n",
      "Epoch: 298, Loss: 0.013819612562656403\n",
      "Epoch: 299, Loss: 0.01843400113284588\n",
      "Epoch: 300, Loss: 0.014475640840828419\n",
      "Epoch: 301, Loss: 0.021851474419236183\n",
      "Epoch: 302, Loss: 0.030698193237185478\n",
      "Epoch: 303, Loss: 0.039862532168626785\n",
      "Epoch: 304, Loss: 0.03865653648972511\n",
      "Epoch: 305, Loss: 0.021968713030219078\n",
      "Epoch: 306, Loss: 0.021927565336227417\n",
      "Epoch: 307, Loss: 0.024792158976197243\n",
      "Epoch: 308, Loss: 0.02301182597875595\n",
      "Epoch: 309, Loss: 0.018989598378539085\n",
      "Epoch: 310, Loss: 0.022758547216653824\n",
      "Epoch: 311, Loss: 0.011455313302576542\n",
      "Epoch: 312, Loss: 0.022508686408400536\n",
      "Epoch: 313, Loss: 0.021899735555052757\n",
      "Epoch: 314, Loss: 0.01547400001436472\n",
      "Epoch: 315, Loss: 0.03831884264945984\n",
      "Epoch: 316, Loss: 0.02647625282406807\n",
      "Epoch: 317, Loss: 0.02810693345963955\n",
      "Epoch: 318, Loss: 0.025073688477277756\n",
      "Epoch: 319, Loss: 0.03255845978856087\n",
      "Epoch: 320, Loss: 0.018310755491256714\n",
      "Epoch: 321, Loss: 0.023232251405715942\n",
      "Epoch: 322, Loss: 0.019853778183460236\n",
      "Epoch: 323, Loss: 0.013678225688636303\n",
      "Epoch: 324, Loss: 0.018182003870606422\n",
      "Epoch: 325, Loss: 0.020063331350684166\n",
      "Epoch: 326, Loss: 0.025121545419096947\n",
      "Epoch: 327, Loss: 0.017204267904162407\n",
      "Epoch: 328, Loss: 0.009882668033242226\n",
      "Epoch: 329, Loss: 0.021685926243662834\n",
      "Epoch: 330, Loss: 0.011309079825878143\n",
      "Epoch: 331, Loss: 0.02215220034122467\n",
      "Epoch: 332, Loss: 0.017772527411580086\n",
      "Epoch: 333, Loss: 0.03190292418003082\n",
      "Epoch: 334, Loss: 0.027126934379339218\n",
      "Epoch: 335, Loss: 0.017635207623243332\n",
      "Epoch: 336, Loss: 0.021231213584542274\n",
      "Epoch: 337, Loss: 0.020624687895178795\n",
      "Epoch: 338, Loss: 0.016807373613119125\n",
      "Epoch: 339, Loss: 0.024638941511511803\n",
      "Epoch: 340, Loss: 0.023041749373078346\n",
      "Epoch: 341, Loss: 0.024210693314671516\n",
      "Epoch: 342, Loss: 0.022691577672958374\n",
      "Epoch: 343, Loss: 0.020413460209965706\n",
      "Epoch: 344, Loss: 0.022056492045521736\n",
      "Epoch: 345, Loss: 0.017900384962558746\n",
      "Epoch: 346, Loss: 0.026769516989588737\n",
      "Epoch: 347, Loss: 0.0248565636575222\n",
      "Epoch: 348, Loss: 0.02540826052427292\n",
      "Epoch: 349, Loss: 0.011610958725214005\n",
      "Epoch: 350, Loss: 0.019910190254449844\n",
      "Epoch: 351, Loss: 0.010299043729901314\n",
      "Epoch: 352, Loss: 0.015159253031015396\n",
      "Epoch: 353, Loss: 0.02220926247537136\n",
      "Epoch: 354, Loss: 0.02170521579682827\n",
      "Epoch: 355, Loss: 0.017722241580486298\n",
      "Epoch: 356, Loss: 0.025345103815197945\n",
      "Epoch: 357, Loss: 0.028341110795736313\n",
      "Epoch: 358, Loss: 0.02910688705742359\n",
      "Epoch: 359, Loss: 0.028458794578909874\n",
      "Epoch: 360, Loss: 0.032000891864299774\n",
      "Epoch: 361, Loss: 0.02628832682967186\n",
      "Epoch: 362, Loss: 0.02610165812075138\n",
      "Epoch: 363, Loss: 0.02608545310795307\n",
      "Epoch: 364, Loss: 0.012962848879396915\n",
      "Epoch: 365, Loss: 0.017265615984797478\n",
      "Epoch: 366, Loss: 0.009640309028327465\n",
      "Epoch: 367, Loss: 0.019904738292098045\n",
      "Epoch: 368, Loss: 0.03278939053416252\n",
      "Epoch: 369, Loss: 0.01939298026263714\n",
      "Epoch: 370, Loss: 0.023729795590043068\n",
      "Epoch: 371, Loss: 0.027871882542967796\n",
      "Epoch: 372, Loss: 0.01961669884622097\n",
      "Epoch: 373, Loss: 0.011996428482234478\n",
      "Epoch: 374, Loss: 0.017647871747612953\n",
      "Epoch: 375, Loss: 0.02142827957868576\n",
      "Epoch: 376, Loss: 0.014655211940407753\n",
      "Epoch: 377, Loss: 0.028163651004433632\n",
      "Epoch: 378, Loss: 0.04327275976538658\n",
      "Epoch: 379, Loss: 0.03405303508043289\n",
      "Epoch: 380, Loss: 0.03346375748515129\n",
      "Epoch: 381, Loss: 0.01618366688489914\n",
      "Epoch: 382, Loss: 0.022242596372961998\n",
      "Epoch: 383, Loss: 0.025966715067625046\n",
      "Epoch: 384, Loss: 0.025491584092378616\n",
      "Epoch: 385, Loss: 0.01901145465672016\n",
      "Epoch: 386, Loss: 0.018536711111664772\n",
      "Epoch: 387, Loss: 0.009626702405512333\n",
      "Epoch: 388, Loss: 0.020063180476427078\n",
      "Epoch: 389, Loss: 0.017346473410725594\n",
      "Epoch: 390, Loss: 0.0171214547008276\n",
      "Epoch: 391, Loss: 0.02002345584332943\n",
      "Epoch: 392, Loss: 0.024432189762592316\n",
      "Epoch: 393, Loss: 0.019428256899118423\n",
      "Epoch: 394, Loss: 0.01844402402639389\n",
      "Epoch: 395, Loss: 0.023763321340084076\n",
      "Epoch: 396, Loss: 0.01869361475110054\n",
      "Epoch: 397, Loss: 0.02744954079389572\n",
      "Epoch: 398, Loss: 0.017833784222602844\n",
      "Epoch: 399, Loss: 0.0203804112970829\n",
      "Epoch: 400, Loss: 0.025419073179364204\n",
      "Epoch: 401, Loss: 0.015638936311006546\n",
      "Epoch: 402, Loss: 0.029421167448163033\n",
      "Epoch: 403, Loss: 0.020782364532351494\n",
      "Epoch: 404, Loss: 0.024818042293190956\n",
      "Epoch: 405, Loss: 0.01094757579267025\n",
      "Epoch: 406, Loss: 0.019743094220757484\n",
      "Epoch: 407, Loss: 0.02501394785940647\n",
      "Epoch: 408, Loss: 0.01858186163008213\n",
      "Epoch: 409, Loss: 0.01678992062807083\n",
      "Epoch: 410, Loss: 0.026383956894278526\n",
      "Epoch: 411, Loss: 0.02042834274470806\n",
      "Epoch: 412, Loss: 0.018182771280407906\n",
      "Epoch: 413, Loss: 0.023113926872611046\n",
      "Epoch: 414, Loss: 0.02291589416563511\n",
      "Epoch: 415, Loss: 0.025944756343960762\n",
      "Epoch: 416, Loss: 0.019119175150990486\n",
      "Epoch: 417, Loss: 0.018959518522024155\n",
      "Epoch: 418, Loss: 0.01920163631439209\n",
      "Epoch: 419, Loss: 0.02048926055431366\n",
      "Epoch: 420, Loss: 0.018732307478785515\n",
      "Epoch: 421, Loss: 0.01685132272541523\n",
      "Epoch: 422, Loss: 0.013899987563490868\n",
      "Epoch: 423, Loss: 0.011111403815448284\n",
      "Epoch: 424, Loss: 0.022532252594828606\n",
      "Epoch: 425, Loss: 0.01682876981794834\n",
      "Epoch: 426, Loss: 0.022103022783994675\n",
      "Epoch: 427, Loss: 0.02328561432659626\n",
      "Epoch: 428, Loss: 0.01496740709990263\n",
      "Epoch: 429, Loss: 0.008205967955291271\n",
      "Epoch: 430, Loss: 0.021615155041217804\n",
      "Epoch: 431, Loss: 0.014760429039597511\n",
      "Epoch: 432, Loss: 0.03447476029396057\n",
      "Epoch: 433, Loss: 0.02754725143313408\n",
      "Epoch: 434, Loss: 0.02402886375784874\n",
      "Epoch: 435, Loss: 0.01465318351984024\n",
      "Epoch: 436, Loss: 0.017631517723202705\n",
      "Epoch: 437, Loss: 0.028405876830220222\n",
      "Epoch: 438, Loss: 0.05141052231192589\n",
      "Epoch: 439, Loss: 0.02818777784705162\n",
      "Epoch: 440, Loss: 0.03549281135201454\n",
      "Epoch: 441, Loss: 0.03736436739563942\n",
      "Epoch: 442, Loss: 0.02411341853439808\n",
      "Epoch: 443, Loss: 0.026379337534308434\n",
      "Epoch: 444, Loss: 0.014668910764157772\n",
      "Epoch: 445, Loss: 0.015941593796014786\n",
      "Epoch: 446, Loss: 0.0242106132209301\n",
      "Epoch: 447, Loss: 0.024761179462075233\n",
      "Epoch: 448, Loss: 0.017443735152482986\n",
      "Epoch: 449, Loss: 0.02260393463075161\n",
      "Epoch: 450, Loss: 0.03138624504208565\n",
      "Epoch: 451, Loss: 0.025227708742022514\n",
      "Epoch: 452, Loss: 0.03258970007300377\n",
      "Epoch: 453, Loss: 0.036410532891750336\n",
      "Epoch: 454, Loss: 0.02682734839618206\n",
      "Epoch: 455, Loss: 0.019083501771092415\n",
      "Epoch: 456, Loss: 0.018569091334939003\n",
      "Epoch: 457, Loss: 0.02426905743777752\n",
      "Epoch: 458, Loss: 0.03172403201460838\n",
      "Epoch: 459, Loss: 0.025704553350806236\n",
      "Epoch: 460, Loss: 0.02288716286420822\n",
      "Epoch: 461, Loss: 0.02425924502313137\n",
      "Epoch: 462, Loss: 0.02927335351705551\n",
      "Epoch: 463, Loss: 0.018407318741083145\n",
      "Epoch: 464, Loss: 0.03158044442534447\n",
      "Epoch: 465, Loss: 0.025462541729211807\n",
      "Epoch: 466, Loss: 0.02442358434200287\n",
      "Epoch: 467, Loss: 0.010591311380267143\n",
      "Epoch: 468, Loss: 0.01946798525750637\n",
      "Epoch: 469, Loss: 0.024047816172242165\n",
      "Epoch: 470, Loss: 0.011998632922768593\n",
      "Epoch: 471, Loss: 0.02104218862950802\n",
      "Epoch: 472, Loss: 0.01629081927239895\n",
      "Epoch: 473, Loss: 0.0206806231290102\n",
      "Epoch: 474, Loss: 0.01595272868871689\n",
      "Epoch: 475, Loss: 0.026282669976353645\n",
      "Epoch: 476, Loss: 0.02296866849064827\n",
      "Epoch: 477, Loss: 0.02048288844525814\n",
      "Epoch: 478, Loss: 0.018236475065350533\n",
      "Epoch: 479, Loss: 0.028989167883992195\n",
      "Epoch: 480, Loss: 0.02017224207520485\n",
      "Epoch: 481, Loss: 0.014746471308171749\n",
      "Epoch: 482, Loss: 0.01833779737353325\n",
      "Epoch: 483, Loss: 0.021800562739372253\n",
      "Epoch: 484, Loss: 0.01929428055882454\n",
      "Epoch: 485, Loss: 0.017938289791345596\n",
      "Epoch: 486, Loss: 0.016159191727638245\n",
      "Epoch: 487, Loss: 0.010875539854168892\n",
      "Epoch: 488, Loss: 0.022513633593916893\n",
      "Epoch: 489, Loss: 0.019573604688048363\n",
      "Epoch: 490, Loss: 0.02079254575073719\n",
      "Epoch: 491, Loss: 0.02020871825516224\n",
      "Epoch: 492, Loss: 0.01972888596355915\n",
      "Epoch: 493, Loss: 0.016500156372785568\n",
      "Epoch: 494, Loss: 0.02188180573284626\n",
      "Epoch: 495, Loss: 0.018463432788848877\n",
      "Epoch: 496, Loss: 0.026643607765436172\n",
      "Epoch: 497, Loss: 0.02274821139872074\n",
      "Epoch: 498, Loss: 0.0105171799659729\n",
      "Epoch: 499, Loss: 0.022337330505251884\n",
      "Epoch: 500, Loss: 0.024481134489178658\n",
      "Epoch: 501, Loss: 0.019795706495642662\n",
      "Epoch: 502, Loss: 0.015362454578280449\n",
      "Epoch: 503, Loss: 0.01919635199010372\n",
      "Epoch: 504, Loss: 0.011631214059889317\n",
      "Epoch: 505, Loss: 0.016470491886138916\n",
      "Epoch: 506, Loss: 0.02017238736152649\n",
      "Epoch: 507, Loss: 0.01814008131623268\n",
      "Epoch: 508, Loss: 0.020018506795167923\n",
      "Epoch: 509, Loss: 0.023281849920749664\n",
      "Epoch: 510, Loss: 0.02115491032600403\n",
      "Epoch: 511, Loss: 0.020077263936400414\n",
      "Epoch: 512, Loss: 0.03564983606338501\n",
      "Epoch: 513, Loss: 0.02784627676010132\n",
      "Epoch: 514, Loss: 0.0238649845123291\n",
      "Epoch: 515, Loss: 0.019230129197239876\n",
      "Epoch: 516, Loss: 0.02128477208316326\n",
      "Epoch: 517, Loss: 0.011984887532889843\n",
      "Epoch: 518, Loss: 0.021618006750941277\n",
      "Epoch: 519, Loss: 0.021553127095103264\n",
      "Epoch: 520, Loss: 0.01987798698246479\n",
      "Epoch: 521, Loss: 0.03162914142012596\n",
      "Epoch: 522, Loss: 0.021777287125587463\n",
      "Epoch: 523, Loss: 0.018994206562638283\n",
      "Epoch: 524, Loss: 0.02012089639902115\n",
      "Epoch: 525, Loss: 0.012460307218134403\n",
      "Epoch: 526, Loss: 0.03244883939623833\n",
      "Epoch: 527, Loss: 0.027173155918717384\n",
      "Epoch: 528, Loss: 0.026609700173139572\n",
      "Epoch: 529, Loss: 0.021468758583068848\n",
      "Epoch: 530, Loss: 0.01964261196553707\n",
      "Epoch: 531, Loss: 0.016128351911902428\n",
      "Epoch: 532, Loss: 0.0202631913125515\n",
      "Epoch: 533, Loss: 0.025671062991023064\n",
      "Epoch: 534, Loss: 0.01872769370675087\n",
      "Epoch: 535, Loss: 0.01981934905052185\n",
      "Epoch: 536, Loss: 0.0174421314150095\n",
      "Epoch: 537, Loss: 0.022009164094924927\n",
      "Epoch: 538, Loss: 0.01472525205463171\n",
      "Epoch: 539, Loss: 0.013931854628026485\n",
      "Epoch: 540, Loss: 0.01436040922999382\n",
      "Epoch: 541, Loss: 0.02080657333135605\n",
      "Epoch: 542, Loss: 0.023653345182538033\n",
      "Epoch: 543, Loss: 0.017869966104626656\n",
      "Epoch: 544, Loss: 0.0224187932908535\n",
      "Epoch: 545, Loss: 0.018589992076158524\n",
      "Epoch: 546, Loss: 0.025671804323792458\n",
      "Epoch: 547, Loss: 0.018402058631181717\n",
      "Epoch: 548, Loss: 0.015026941895484924\n",
      "Epoch: 549, Loss: 0.024892790243029594\n",
      "Epoch: 550, Loss: 0.015580437146127224\n",
      "Epoch: 551, Loss: 0.020535070449113846\n",
      "Epoch: 552, Loss: 0.016442416235804558\n",
      "Epoch: 553, Loss: 0.019474685192108154\n",
      "Epoch: 554, Loss: 0.01864450052380562\n",
      "Epoch: 555, Loss: 0.0190013125538826\n",
      "Epoch: 556, Loss: 0.021180855110287666\n",
      "Epoch: 557, Loss: 0.02812693826854229\n",
      "Epoch: 558, Loss: 0.024842575192451477\n",
      "Epoch: 559, Loss: 0.024540456011891365\n",
      "Epoch: 560, Loss: 0.02570917457342148\n",
      "Epoch: 561, Loss: 0.022955629974603653\n",
      "Epoch: 562, Loss: 0.023934191092848778\n",
      "Epoch: 563, Loss: 0.02695903182029724\n",
      "Epoch: 564, Loss: 0.01732947863638401\n",
      "Epoch: 565, Loss: 0.015350149013102055\n",
      "Epoch: 566, Loss: 0.017910968512296677\n",
      "Epoch: 567, Loss: 0.01629621349275112\n",
      "Epoch: 568, Loss: 0.019162490963935852\n",
      "Epoch: 569, Loss: 0.014635083265602589\n",
      "Epoch: 570, Loss: 0.015353342518210411\n",
      "Epoch: 571, Loss: 0.0261753648519516\n",
      "Epoch: 572, Loss: 0.022276857867836952\n",
      "Epoch: 573, Loss: 0.035519663244485855\n",
      "Epoch: 574, Loss: 0.014364934526383877\n",
      "Epoch: 575, Loss: 0.03725651279091835\n",
      "Epoch: 576, Loss: 0.02817399799823761\n",
      "Epoch: 577, Loss: 0.02247457578778267\n",
      "Epoch: 578, Loss: 0.013037963770329952\n",
      "Epoch: 579, Loss: 0.02522600255906582\n",
      "Epoch: 580, Loss: 0.020551832392811775\n",
      "Epoch: 581, Loss: 0.018164973706007004\n",
      "Epoch: 582, Loss: 0.02422226034104824\n",
      "Epoch: 583, Loss: 0.023968221619725227\n",
      "Epoch: 584, Loss: 0.03813446685671806\n",
      "Epoch: 585, Loss: 0.016447102651000023\n",
      "Epoch: 586, Loss: 0.044481467455625534\n",
      "Epoch: 587, Loss: 0.04221153259277344\n",
      "Epoch: 588, Loss: 0.02759343571960926\n",
      "Epoch: 589, Loss: 0.023978544399142265\n",
      "Epoch: 590, Loss: 0.022502750158309937\n",
      "Epoch: 591, Loss: 0.017058996483683586\n",
      "Epoch: 592, Loss: 0.00909314677119255\n",
      "Epoch: 593, Loss: 0.016597900539636612\n",
      "Epoch: 594, Loss: 0.023942360654473305\n",
      "Epoch: 595, Loss: 0.020894469693303108\n",
      "Epoch: 596, Loss: 0.014098651707172394\n",
      "Epoch: 597, Loss: 0.019034458324313164\n",
      "Epoch: 598, Loss: 0.017371905967593193\n",
      "Epoch: 599, Loss: 0.01263319980353117\n",
      "Epoch: 600, Loss: 0.01566055789589882\n",
      "Epoch: 601, Loss: 0.012873765081167221\n",
      "Epoch: 602, Loss: 0.022461889311671257\n",
      "Epoch: 603, Loss: 0.017731737345457077\n",
      "Epoch: 604, Loss: 0.01297363918274641\n",
      "Epoch: 605, Loss: 0.015193973667919636\n",
      "Epoch: 606, Loss: 0.010058747604489326\n",
      "Epoch: 607, Loss: 0.022469406947493553\n",
      "Epoch: 608, Loss: 0.0141757195815444\n",
      "Epoch: 609, Loss: 0.02106240764260292\n",
      "Epoch: 610, Loss: 0.014433376491069794\n",
      "Epoch: 611, Loss: 0.011090854182839394\n",
      "Epoch: 612, Loss: 0.02397432178258896\n",
      "Epoch: 613, Loss: 0.03475034236907959\n",
      "Epoch: 614, Loss: 0.013414802961051464\n",
      "Epoch: 615, Loss: 0.021255237981677055\n",
      "Epoch: 616, Loss: 0.02119480073451996\n",
      "Epoch: 617, Loss: 0.021304013207554817\n",
      "Epoch: 618, Loss: 0.017357122153043747\n",
      "Epoch: 619, Loss: 0.011584790423512459\n",
      "Epoch: 620, Loss: 0.022340480238199234\n",
      "Epoch: 621, Loss: 0.02547428384423256\n",
      "Epoch: 622, Loss: 0.018077317625284195\n",
      "Epoch: 623, Loss: 0.010431610979139805\n",
      "Epoch: 624, Loss: 0.014909160323441029\n",
      "Epoch: 625, Loss: 0.016872914507985115\n",
      "Epoch: 626, Loss: 0.022857921198010445\n",
      "Epoch: 627, Loss: 0.017515961080789566\n",
      "Epoch: 628, Loss: 0.01670139655470848\n",
      "Epoch: 629, Loss: 0.015032603405416012\n",
      "Epoch: 630, Loss: 0.0136212557554245\n",
      "Epoch: 631, Loss: 0.014427845366299152\n",
      "Epoch: 632, Loss: 0.019328292459249496\n",
      "Epoch: 633, Loss: 0.009653910994529724\n",
      "Epoch: 634, Loss: 0.012991887517273426\n",
      "Epoch: 635, Loss: 0.018971320241689682\n",
      "Epoch: 636, Loss: 0.01723402924835682\n",
      "Epoch: 637, Loss: 0.01877918466925621\n",
      "Epoch: 638, Loss: 0.02136608585715294\n",
      "Epoch: 639, Loss: 0.02122921496629715\n",
      "Epoch: 640, Loss: 0.019076544791460037\n",
      "Epoch: 641, Loss: 0.021109120920300484\n",
      "Epoch: 642, Loss: 0.0260417852550745\n",
      "Epoch: 643, Loss: 0.020553315058350563\n",
      "Epoch: 644, Loss: 0.027013324201107025\n",
      "Epoch: 645, Loss: 0.017177294939756393\n",
      "Epoch: 646, Loss: 0.02139388956129551\n",
      "Epoch: 647, Loss: 0.020623542368412018\n",
      "Epoch: 648, Loss: 0.014369496144354343\n",
      "Epoch: 649, Loss: 0.019972309470176697\n",
      "Epoch: 650, Loss: 0.01283648144453764\n",
      "Epoch: 651, Loss: 0.020529650151729584\n",
      "Epoch: 652, Loss: 0.015428289771080017\n",
      "Epoch: 653, Loss: 0.019541457295417786\n",
      "Epoch: 654, Loss: 0.013026426546275616\n",
      "Epoch: 655, Loss: 0.019785892218351364\n",
      "Epoch: 656, Loss: 0.017804332077503204\n",
      "Epoch: 657, Loss: 0.02123253419995308\n",
      "Epoch: 658, Loss: 0.014838073402643204\n",
      "Epoch: 659, Loss: 0.016927570104599\n",
      "Epoch: 660, Loss: 0.02346247062087059\n",
      "Epoch: 661, Loss: 0.014459490776062012\n",
      "Epoch: 662, Loss: 0.010704313404858112\n",
      "Epoch: 663, Loss: 0.02284231223165989\n",
      "Epoch: 664, Loss: 0.016849979758262634\n",
      "Epoch: 665, Loss: 0.01837056316435337\n",
      "Epoch: 666, Loss: 0.023764779791235924\n",
      "Epoch: 667, Loss: 0.019607899710536003\n",
      "Epoch: 668, Loss: 0.01286900695413351\n",
      "Epoch: 669, Loss: 0.01579962484538555\n",
      "Epoch: 670, Loss: 0.01686026155948639\n",
      "Epoch: 671, Loss: 0.017487743869423866\n",
      "Epoch: 672, Loss: 0.014213860034942627\n",
      "Epoch: 673, Loss: 0.01675027795135975\n",
      "Epoch: 674, Loss: 0.02071402035653591\n",
      "Epoch: 675, Loss: 0.008760382421314716\n",
      "Epoch: 676, Loss: 0.016638511791825294\n",
      "Epoch: 677, Loss: 0.01945461519062519\n",
      "Epoch: 678, Loss: 0.014939668588340282\n",
      "Epoch: 679, Loss: 0.016411805525422096\n",
      "Epoch: 680, Loss: 0.008810247294604778\n",
      "Epoch: 681, Loss: 0.014366895891726017\n",
      "Epoch: 682, Loss: 0.0162399522960186\n",
      "Epoch: 683, Loss: 0.022694025188684464\n",
      "Epoch: 684, Loss: 0.014914711937308311\n",
      "Epoch: 685, Loss: 0.01281821634620428\n",
      "Epoch: 686, Loss: 0.012907030992209911\n",
      "Epoch: 687, Loss: 0.018262360244989395\n",
      "Epoch: 688, Loss: 0.017041176557540894\n",
      "Epoch: 689, Loss: 0.021105721592903137\n",
      "Epoch: 690, Loss: 0.022304318845272064\n",
      "Epoch: 691, Loss: 0.02351277507841587\n",
      "Epoch: 692, Loss: 0.02068701758980751\n",
      "Epoch: 693, Loss: 0.028658146038651466\n",
      "Epoch: 694, Loss: 0.021746763959527016\n",
      "Epoch: 695, Loss: 0.01902608759701252\n",
      "Epoch: 696, Loss: 0.008911332115530968\n",
      "Epoch: 697, Loss: 0.018061961978673935\n",
      "Epoch: 698, Loss: 0.019528284668922424\n",
      "Epoch: 699, Loss: 0.01725182868540287\n",
      "Epoch: 700, Loss: 0.010905415751039982\n",
      "Epoch: 701, Loss: 0.013954904861748219\n",
      "Epoch: 702, Loss: 0.00966294202953577\n",
      "Epoch: 703, Loss: 0.01416562870144844\n",
      "Epoch: 704, Loss: 0.013512682169675827\n",
      "Epoch: 705, Loss: 0.020038438960909843\n",
      "Epoch: 706, Loss: 0.017125006765127182\n",
      "Epoch: 707, Loss: 0.010638035833835602\n",
      "Epoch: 708, Loss: 0.012756049633026123\n",
      "Epoch: 709, Loss: 0.020074760541319847\n",
      "Epoch: 710, Loss: 0.020194116979837418\n",
      "Epoch: 711, Loss: 0.01335827261209488\n",
      "Epoch: 712, Loss: 0.01832643337547779\n",
      "Epoch: 713, Loss: 0.01841978169977665\n",
      "Epoch: 714, Loss: 0.01307532750070095\n",
      "Epoch: 715, Loss: 0.015028074383735657\n",
      "Epoch: 716, Loss: 0.011958856135606766\n",
      "Epoch: 717, Loss: 0.015642283484339714\n",
      "Epoch: 718, Loss: 0.02052249200642109\n",
      "Epoch: 719, Loss: 0.010588711127638817\n",
      "Epoch: 720, Loss: 0.01664670743048191\n",
      "Epoch: 721, Loss: 0.013508436270058155\n",
      "Epoch: 722, Loss: 0.013164369389414787\n",
      "Epoch: 723, Loss: 0.02005865052342415\n",
      "Epoch: 724, Loss: 0.016034580767154694\n",
      "Epoch: 725, Loss: 0.010625418275594711\n",
      "Epoch: 726, Loss: 0.022545350715517998\n",
      "Epoch: 727, Loss: 0.02624449133872986\n",
      "Epoch: 728, Loss: 0.024974167346954346\n",
      "Epoch: 729, Loss: 0.0175735205411911\n",
      "Epoch: 730, Loss: 0.03144971653819084\n",
      "Epoch: 731, Loss: 0.021702131256461143\n",
      "Epoch: 732, Loss: 0.021962901577353477\n",
      "Epoch: 733, Loss: 0.011735797859728336\n",
      "Epoch: 734, Loss: 0.015567309223115444\n",
      "Epoch: 735, Loss: 0.017179220914840698\n",
      "Epoch: 736, Loss: 0.010037561878561974\n",
      "Epoch: 737, Loss: 0.015790266916155815\n",
      "Epoch: 738, Loss: 0.011573385447263718\n",
      "Epoch: 739, Loss: 0.013334633782505989\n",
      "Epoch: 740, Loss: 0.014431018382310867\n",
      "Epoch: 741, Loss: 0.01330776046961546\n",
      "Epoch: 742, Loss: 0.032401733100414276\n",
      "Epoch: 743, Loss: 0.017150061205029488\n",
      "Epoch: 744, Loss: 0.02357945218682289\n",
      "Epoch: 745, Loss: 0.021694304421544075\n",
      "Epoch: 746, Loss: 0.016734778881072998\n",
      "Epoch: 747, Loss: 0.01997213065624237\n",
      "Epoch: 748, Loss: 0.01411617174744606\n",
      "Epoch: 749, Loss: 0.01641465350985527\n",
      "Epoch: 750, Loss: 0.01874583214521408\n",
      "Epoch: 751, Loss: 0.019559809938073158\n",
      "Epoch: 752, Loss: 0.015805689617991447\n",
      "Epoch: 753, Loss: 0.017592811957001686\n",
      "Epoch: 754, Loss: 0.014254007488489151\n",
      "Epoch: 755, Loss: 0.015305787324905396\n",
      "Epoch: 756, Loss: 0.01804940216243267\n",
      "Epoch: 757, Loss: 0.016824962571263313\n",
      "Epoch: 758, Loss: 0.01572669856250286\n",
      "Epoch: 759, Loss: 0.010207346640527248\n",
      "Epoch: 760, Loss: 0.016423651948571205\n",
      "Epoch: 761, Loss: 0.017323598265647888\n",
      "Epoch: 762, Loss: 0.01692054606974125\n",
      "Epoch: 763, Loss: 0.01930694282054901\n",
      "Epoch: 764, Loss: 0.024815235286951065\n",
      "Epoch: 765, Loss: 0.01780475117266178\n",
      "Epoch: 766, Loss: 0.014184674248099327\n",
      "Epoch: 767, Loss: 0.02880755625665188\n",
      "Epoch: 768, Loss: 0.015473986975848675\n",
      "Epoch: 769, Loss: 0.008943036198616028\n",
      "Epoch: 770, Loss: 0.016557367518544197\n",
      "Epoch: 771, Loss: 0.016092464327812195\n",
      "Epoch: 772, Loss: 0.01929890550673008\n",
      "Epoch: 773, Loss: 0.014611615799367428\n",
      "Epoch: 774, Loss: 0.0228863675147295\n",
      "Epoch: 775, Loss: 0.020631808787584305\n",
      "Epoch: 776, Loss: 0.022090133279561996\n",
      "Epoch: 777, Loss: 0.02410285361111164\n",
      "Epoch: 778, Loss: 0.019130930304527283\n",
      "Epoch: 779, Loss: 0.013523321598768234\n",
      "Epoch: 780, Loss: 0.015479632653295994\n",
      "Epoch: 781, Loss: 0.009686645120382309\n",
      "Epoch: 782, Loss: 0.01885196939110756\n",
      "Epoch: 783, Loss: 0.015585949644446373\n",
      "Epoch: 784, Loss: 0.024908171966671944\n",
      "Epoch: 785, Loss: 0.018100572749972343\n",
      "Epoch: 786, Loss: 0.010721034370362759\n",
      "Epoch: 787, Loss: 0.01862926222383976\n",
      "Epoch: 788, Loss: 0.02036707103252411\n",
      "Epoch: 789, Loss: 0.019370267167687416\n",
      "Epoch: 790, Loss: 0.016982274129986763\n",
      "Epoch: 791, Loss: 0.017977718263864517\n",
      "Epoch: 792, Loss: 0.01619121804833412\n",
      "Epoch: 793, Loss: 0.01267789863049984\n",
      "Epoch: 794, Loss: 0.015588201582431793\n",
      "Epoch: 795, Loss: 0.012433428317308426\n",
      "Epoch: 796, Loss: 0.015524612739682198\n",
      "Epoch: 797, Loss: 0.013996966183185577\n",
      "Epoch: 798, Loss: 0.016050344333052635\n",
      "Epoch: 799, Loss: 0.018360376358032227\n",
      "Epoch: 800, Loss: 0.017975086346268654\n",
      "Epoch: 801, Loss: 0.01512486208230257\n",
      "Epoch: 802, Loss: 0.014528734609484673\n",
      "Epoch: 803, Loss: 0.017578914761543274\n",
      "Epoch: 804, Loss: 0.01232647243887186\n",
      "Epoch: 805, Loss: 0.024731598794460297\n",
      "Epoch: 806, Loss: 0.03177542984485626\n",
      "Epoch: 807, Loss: 0.03477414697408676\n",
      "Epoch: 808, Loss: 0.030473042279481888\n",
      "Epoch: 809, Loss: 0.030161980539560318\n",
      "Epoch: 810, Loss: 0.023048974573612213\n",
      "Epoch: 811, Loss: 0.02053011581301689\n",
      "Epoch: 812, Loss: 0.02164698950946331\n",
      "Epoch: 813, Loss: 0.014814511872828007\n",
      "Epoch: 814, Loss: 0.021437060087919235\n",
      "Epoch: 815, Loss: 0.01645624078810215\n",
      "Epoch: 816, Loss: 0.013615957461297512\n",
      "Epoch: 817, Loss: 0.015037136152386665\n",
      "Epoch: 818, Loss: 0.013156921602785587\n",
      "Epoch: 819, Loss: 0.00878806971013546\n",
      "Epoch: 820, Loss: 0.013658112846314907\n",
      "Epoch: 821, Loss: 0.014958011917769909\n",
      "Epoch: 822, Loss: 0.01896010711789131\n",
      "Epoch: 823, Loss: 0.015521208755671978\n",
      "Epoch: 824, Loss: 0.01740350015461445\n",
      "Epoch: 825, Loss: 0.013817009516060352\n",
      "Epoch: 826, Loss: 0.015373952686786652\n",
      "Epoch: 827, Loss: 0.015055201947689056\n",
      "Epoch: 828, Loss: 0.016457045450806618\n",
      "Epoch: 829, Loss: 0.02150522544980049\n",
      "Epoch: 830, Loss: 0.024177776649594307\n",
      "Epoch: 831, Loss: 0.02006523311138153\n",
      "Epoch: 832, Loss: 0.0400170162320137\n",
      "Epoch: 833, Loss: 0.028820551931858063\n",
      "Epoch: 834, Loss: 0.02302919514477253\n",
      "Epoch: 835, Loss: 0.02786739356815815\n",
      "Epoch: 836, Loss: 0.01452508382499218\n",
      "Epoch: 837, Loss: 0.019272617995738983\n",
      "Epoch: 838, Loss: 0.023064495995640755\n",
      "Epoch: 839, Loss: 0.014068091288208961\n",
      "Epoch: 840, Loss: 0.03628105670213699\n",
      "Epoch: 841, Loss: 0.018175717443227768\n",
      "Epoch: 842, Loss: 0.020319342613220215\n",
      "Epoch: 843, Loss: 0.0168148186057806\n",
      "Epoch: 844, Loss: 0.016072386875748634\n",
      "Epoch: 845, Loss: 0.01724754273891449\n",
      "Epoch: 846, Loss: 0.013146227225661278\n",
      "Epoch: 847, Loss: 0.020103970542550087\n",
      "Epoch: 848, Loss: 0.015211196616292\n",
      "Epoch: 849, Loss: 0.012987451627850533\n",
      "Epoch: 850, Loss: 0.019812099635601044\n",
      "Epoch: 851, Loss: 0.017955297604203224\n",
      "Epoch: 852, Loss: 0.013516695238649845\n",
      "Epoch: 853, Loss: 0.018191950395703316\n",
      "Epoch: 854, Loss: 0.012318016961216927\n",
      "Epoch: 855, Loss: 0.01995183154940605\n",
      "Epoch: 856, Loss: 0.011450568214058876\n",
      "Epoch: 857, Loss: 0.014826412312686443\n",
      "Epoch: 858, Loss: 0.0164365042001009\n",
      "Epoch: 859, Loss: 0.019113615155220032\n",
      "Epoch: 860, Loss: 0.016468822956085205\n",
      "Epoch: 861, Loss: 0.013457013294100761\n",
      "Epoch: 862, Loss: 0.019241033121943474\n",
      "Epoch: 863, Loss: 0.025679392740130424\n",
      "Epoch: 864, Loss: 0.03141127899289131\n",
      "Epoch: 865, Loss: 0.018900185823440552\n",
      "Epoch: 866, Loss: 0.01979197934269905\n",
      "Epoch: 867, Loss: 0.02154567465186119\n",
      "Epoch: 868, Loss: 0.01855994574725628\n",
      "Epoch: 869, Loss: 0.015717357397079468\n",
      "Epoch: 870, Loss: 0.020657628774642944\n",
      "Epoch: 871, Loss: 0.018927916884422302\n",
      "Epoch: 872, Loss: 0.016057681292295456\n",
      "Epoch: 873, Loss: 0.014449824579060078\n",
      "Epoch: 874, Loss: 0.02249826304614544\n",
      "Epoch: 875, Loss: 0.016208486631512642\n",
      "Epoch: 876, Loss: 0.021258579567074776\n",
      "Epoch: 877, Loss: 0.021736981347203255\n",
      "Epoch: 878, Loss: 0.013556140474975109\n",
      "Epoch: 879, Loss: 0.011734782718122005\n",
      "Epoch: 880, Loss: 0.02348666451871395\n",
      "Epoch: 881, Loss: 0.013509945012629032\n",
      "Epoch: 882, Loss: 0.012511263601481915\n",
      "Epoch: 883, Loss: 0.013295845128595829\n",
      "Epoch: 884, Loss: 0.016569798812270164\n",
      "Epoch: 885, Loss: 0.01357542909681797\n",
      "Epoch: 886, Loss: 0.012364045716822147\n",
      "Epoch: 887, Loss: 0.014541362412273884\n",
      "Epoch: 888, Loss: 0.009853014722466469\n",
      "Epoch: 889, Loss: 0.012591528706252575\n",
      "Epoch: 890, Loss: 0.016834529116749763\n",
      "Epoch: 891, Loss: 0.016945170238614082\n",
      "Epoch: 892, Loss: 0.020076431334018707\n",
      "Epoch: 893, Loss: 0.02308916673064232\n",
      "Epoch: 894, Loss: 0.017190860584378242\n",
      "Epoch: 895, Loss: 0.016498396173119545\n",
      "Epoch: 896, Loss: 0.013618200086057186\n",
      "Epoch: 897, Loss: 0.009035877883434296\n",
      "Epoch: 898, Loss: 0.014677810482680798\n",
      "Epoch: 899, Loss: 0.013135753571987152\n",
      "Epoch: 900, Loss: 0.01622072048485279\n",
      "Epoch: 901, Loss: 0.014617271721363068\n",
      "Epoch: 902, Loss: 0.023548580706119537\n",
      "Epoch: 903, Loss: 0.012116563506424427\n",
      "Epoch: 904, Loss: 0.020030200481414795\n",
      "Epoch: 905, Loss: 0.012306452728807926\n",
      "Epoch: 906, Loss: 0.023765794932842255\n",
      "Epoch: 907, Loss: 0.017213372513651848\n",
      "Epoch: 908, Loss: 0.016352934762835503\n",
      "Epoch: 909, Loss: 0.016366206109523773\n",
      "Epoch: 910, Loss: 0.02233561873435974\n",
      "Epoch: 911, Loss: 0.01749160885810852\n",
      "Epoch: 912, Loss: 0.014391981065273285\n",
      "Epoch: 913, Loss: 0.013049498200416565\n",
      "Epoch: 914, Loss: 0.01842126064002514\n",
      "Epoch: 915, Loss: 0.018836773931980133\n",
      "Epoch: 916, Loss: 0.015674347057938576\n",
      "Epoch: 917, Loss: 0.015003779903054237\n",
      "Epoch: 918, Loss: 0.0163130946457386\n",
      "Epoch: 919, Loss: 0.015217743813991547\n",
      "Epoch: 920, Loss: 0.008972974494099617\n",
      "Epoch: 921, Loss: 0.023612136021256447\n",
      "Epoch: 922, Loss: 0.021786335855722427\n",
      "Epoch: 923, Loss: 0.02684962749481201\n",
      "Epoch: 924, Loss: 0.017623459920287132\n",
      "Epoch: 925, Loss: 0.019907884299755096\n",
      "Epoch: 926, Loss: 0.03385059908032417\n",
      "Epoch: 927, Loss: 0.018247127532958984\n",
      "Epoch: 928, Loss: 0.029217900708317757\n",
      "Epoch: 929, Loss: 0.018684925511479378\n",
      "Epoch: 930, Loss: 0.01571308635175228\n",
      "Epoch: 931, Loss: 0.01608058623969555\n",
      "Epoch: 932, Loss: 0.010677660815417767\n",
      "Epoch: 933, Loss: 0.016272572800517082\n",
      "Epoch: 934, Loss: 0.008820575661957264\n",
      "Epoch: 935, Loss: 0.017824137583374977\n",
      "Epoch: 936, Loss: 0.015410003252327442\n",
      "Epoch: 937, Loss: 0.007890617474913597\n",
      "Epoch: 938, Loss: 0.016098253428936005\n",
      "Epoch: 939, Loss: 0.013256353326141834\n",
      "Epoch: 940, Loss: 0.01193894911557436\n",
      "Epoch: 941, Loss: 0.021369479596614838\n",
      "Epoch: 942, Loss: 0.018651815131306648\n",
      "Epoch: 943, Loss: 0.016640832647681236\n",
      "Epoch: 944, Loss: 0.01415211334824562\n",
      "Epoch: 945, Loss: 0.01957840658724308\n",
      "Epoch: 946, Loss: 0.015697656199336052\n",
      "Epoch: 947, Loss: 0.016968106850981712\n",
      "Epoch: 948, Loss: 0.02507556416094303\n",
      "Epoch: 949, Loss: 0.01767890155315399\n",
      "Epoch: 950, Loss: 0.013574738055467606\n",
      "Epoch: 951, Loss: 0.015190987847745419\n",
      "Epoch: 952, Loss: 0.025181135162711143\n",
      "Epoch: 953, Loss: 0.014805955812335014\n",
      "Epoch: 954, Loss: 0.01697554811835289\n",
      "Epoch: 955, Loss: 0.03138791024684906\n",
      "Epoch: 956, Loss: 0.019665759056806564\n",
      "Epoch: 957, Loss: 0.037841957062482834\n",
      "Epoch: 958, Loss: 0.01790173165500164\n",
      "Epoch: 959, Loss: 0.018185654655098915\n",
      "Epoch: 960, Loss: 0.013192804530262947\n",
      "Epoch: 961, Loss: 0.028154315426945686\n",
      "Epoch: 962, Loss: 0.009993740357458591\n",
      "Epoch: 963, Loss: 0.024048009887337685\n",
      "Epoch: 964, Loss: 0.01733057014644146\n",
      "Epoch: 965, Loss: 0.01727365329861641\n",
      "Epoch: 966, Loss: 0.015444549731910229\n",
      "Epoch: 967, Loss: 0.016394328325986862\n",
      "Epoch: 968, Loss: 0.013700907118618488\n",
      "Epoch: 969, Loss: 0.011447818018496037\n",
      "Epoch: 970, Loss: 0.014570503495633602\n",
      "Epoch: 971, Loss: 0.012800944037735462\n",
      "Epoch: 972, Loss: 0.024398691952228546\n",
      "Epoch: 973, Loss: 0.01732632890343666\n",
      "Epoch: 974, Loss: 0.014272631146013737\n",
      "Epoch: 975, Loss: 0.008685744367539883\n",
      "Epoch: 976, Loss: 0.019546059891581535\n",
      "Epoch: 977, Loss: 0.016738055273890495\n",
      "Epoch: 978, Loss: 0.01263080257922411\n",
      "Epoch: 979, Loss: 0.01812918670475483\n",
      "Epoch: 980, Loss: 0.020222922787070274\n",
      "Epoch: 981, Loss: 0.01770891435444355\n",
      "Epoch: 982, Loss: 0.013663802295923233\n",
      "Epoch: 983, Loss: 0.012032566592097282\n",
      "Epoch: 984, Loss: 0.009749389253556728\n",
      "Epoch: 985, Loss: 0.02350662462413311\n",
      "Epoch: 986, Loss: 0.0233994722366333\n",
      "Epoch: 987, Loss: 0.013992083258926868\n",
      "Epoch: 988, Loss: 0.041741400957107544\n",
      "Epoch: 989, Loss: 0.033518560230731964\n",
      "Epoch: 990, Loss: 0.03550063818693161\n",
      "Epoch: 991, Loss: 0.01967824064195156\n",
      "Epoch: 992, Loss: 0.023420123383402824\n",
      "Epoch: 993, Loss: 0.016796140000224113\n",
      "Epoch: 994, Loss: 0.01701299473643303\n",
      "Epoch: 995, Loss: 0.014815285801887512\n",
      "Epoch: 996, Loss: 0.023197852075099945\n",
      "Epoch: 997, Loss: 0.021261174231767654\n",
      "Epoch: 998, Loss: 0.032870080322027206\n",
      "Epoch: 999, Loss: 0.016545716673135757\n",
      "Epoch: 1000, Loss: 0.026817280799150467\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "num_epochs = 1000\n",
    "model = model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, targets) in enumerate(train_dataloader):\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {losses.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
